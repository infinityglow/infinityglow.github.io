[{"title":"归并排序","url":"/study/algorithm/divide-and-conquer/merge-sort/","content":"\n## 分治\n\n**分治**（**divide and conquer**）是算法里面的一种经典思想。与减治的通过缩小问题规模来解决问题而有所不同的是，分治采用的是，将一个大问题分成若干个小问题，然后逐一解决小问题，最后将小问题的解合并为原来大问题的解。听起来很抽象？没关系，下面的一个例子你马上就能明白。\n\n小的时候我们一定都玩过类似乐高的玩具，当你花了几天的时间拼出一件作品时，你一定是满满的成就感吧。其实，我们在整个拼接的过程中都用到了分治的思想。要想拼出一栋房子，我们肯定不会一个零件一个零件地拼，而是先将这些零件组合成一个个的小部件（例如屋顶，窗户等），然后把这些小部件拼接起来，组成更大的部件，然后这些大部件再相互拼接，最后拼出一件完整的作品。\n\n![玩具](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/toy.png)\n\n假设整个作品由 n 个零件组成，它由 b 个规模相等的小部件拼接而成，拼接需要 a 次完成，一次拼接的时间为 f(n)。所以，根据这个关系，我们可以写出下面的关系式：\n\n![formula](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/formula0.png)\n\n其中，f(n) 是关于 n 的一个函数，这里我们可以把它视作一次拼接所需要的时间复杂度，Θ(n<sup>d</sup>)，d 代表复杂度的阶数。我们根据 a, b, d 的取值，再借助下面的公式，就可以计算出不同情况下的复杂度了：\n\n![formula](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/formula1.png)\n\n公式具体的证明过程在 [Levitin](https://doc.lagout.org/science/0_Computer%20Science/2_Algorithms/Introduction%20to%20the%20Design%20and%20Analysis%20of%20Algorithms%20%283rd%20ed.%29%20%5BLevitin%202011-10-09%5D.pdf) 算法书的附录里，大家感兴趣可以去自己研究研究，后面的例子在计算复杂度的过程中会直接套用这里的公式。\n\n## 有序数组的合并\n\n将两个有序的数组合并成一个有序的数组就类似于将两个小部件的拼接过程，那具体该怎么实现呢？让我们来举一个例子吧。\n\n假设下面两个数组 a 和 b 要合并，我们需要一个空数组 c 来存放 a 和 b 中的元素。\n\n![array](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/array0.png)\n\n具体步骤如下：\n\n- 第一步：用三个变量 i, j, k 来分别记录数组 a，数组 b 和空数组 c 的索引值。\n\n![array](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/array1.png)\n\n- 第二步：比较 a[i] 和 b[j] 的大小，将小的元素存入到空数组 c 中。\n\n![array](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/array2.png)\n\n- 第三步：较小元素的数组索引值和数组 c 的索引值加 1。\n\n![array](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/array3.png)\n\n- 第四步：如果数组 a 和 b 的其中一个还未完全比较，执行第二步和第三步，否则执行第五步。\n\n![array](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/array4.png)\n\n- 第五步：将剩余数组的元素全部存入到数组 c 中。\n\n![array](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/array5.png)\n\n假设数组 a 和 b 分别有 n / 2 个元素，最好的情况要比较 n / 2 次，最坏的情况要比较 n - 1 次，所以合并有序数组的时间复杂度为 Θ(n)。\n\n## 归并排序\n\n我们知道，只有一个元素的数组一定是有序的，所以归并排序的第一步操作就是将数组对半分割，直到分割到只有一个元素为止。然后再将这些元素两两归并，最后使整个数组有序。因此，归并排序可以像下面这张图那样描述：\n\n![归并排序](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/merge-sort.png)\n\n代码由两个函数实现，一个是我们前面提到的合并有序数组。\n\n```\ndef merge(a, b):\n    i, j, k = 0, 0, 0  # 初始化变量\n    p, q = len(a), len(b)\n    c = [0 for i in range(p+q)]  # 建立空数组\n    while i < p and j < q:\n        if a[i] <= b[j]:\n            c[k] = a[i]; i += 1\n        else:\n            c[k] = b[j]; j += 1\n        k += 1\n        comparison += 1\n    while i < p:\n        c[k] = a[i]\n        i += 1; k += 1\n    while j < q:\n        c[k] = b[j]\n        j += 1; k += 1\n    return c\n```\n\n另一个是我们的主函数 `merge_sort`。\n\n```\ndef merge_sort(array):\n    if len(array) <= 1:\n        return array\n    m = len(array) // 2  # 中间位置\n    A = merge_sort(array[: m])\n    B = merge_sort(array[m:])\n    C = merge(A, B)\n    return C\n```\n\n![demo](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/merge.mp4)\n\n最后来分析一下归并排序的复杂度。前面我们知道归并的复杂度为 Θ(n)，由于分割过程只执行一次基本操作，所以分割的复杂度为 Θ(1)，可以忽略不计。故我们可以得出下面的递归关系式：\n\n![relation](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/images/relation.png)\n\n这个关系式的含义是，对长度为 n 的数组进行排序的时间复杂度等于对两个长度为 n / 2 的数组排序的时间复杂度，再加上分割和归并的时间复杂度 Θ(n)。根据前面的公式，我们可以得到归并排序的时间复杂度为 Θ(nlog n)。由于归并过程需要长度为 n 的空数组，所以归并排序的空间复杂度为 Θ(n)。\n\n归并排序的时间复杂度已经超越了前面讲到的所有排序算法，但它需要牺牲存储空间来实现。后面要讲到的[计数排序](https://infinityglow.github.io/study/algorithm/time-space-tradeoff/counting-sort/)也体现了这种思想。\n\n"},{"title":"插值查找","url":"/study/algorithm/decrease-and-conquer/interpolation-search/","content":"\n## 查字典\n\n如果要在字典里查找 “algorithm” 这个单词，我们肯定不会傻傻地像二分法那样从中间开始查找。相反，我们会从字母 A 开始查找，然后再根据第二个字母在字母表中的位置，找到相应的位置继续查找，这样反复这个过程，直到查到这个单词。\n\n在这一节的内容里，我们会实现类似于查字典的算法。\n\n## 插值查找\n\n**插值查找**（**interpolation search**）是二分查找的改良版。假设有这样一个数组 [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]，我们可以发现，每个相邻元素的差均为 10，呈现出均匀分布。如果要查找元素 70，我们首先可以计算出在数组中小于等于 70 的元素占所有元素的比例的期望值为 p = (70 - 0) / (90 - 0) = 7 / 9，而数组的长度 n 我们知道等于 10，所以我们期望查找的索引值就为 ⌊n × p⌋ = 7，对应的元素为 70，恰好就是我们要找的元素。\n\n这里，我们用一个公式来表示每次查找的期望索引值： \n\n![formula](https://infinityglow.github.io/study/algorithm/decease-and-conquer/interpolation-search/images/formula.png)\n\n其中，l 和 r 分别代表数组的第一个和最后一个索引，key 代表待查找的元素。\n\n跟二分查找一样，如果一次查找失败，数组的长度就相应地减小，再代入上面的公式继续查找，直到查找成功或失败。\n\n```\ndef formula(l, r, key, array):\n    p = (key - array[l]) / (array[r] - array[l])\n    n = r - l\n    idx = int(n * p)\n    return idx\n\ndef interpolation_search(array, key):\n    l = 0; r = len(array) - 1\n    while l <= r:\n        m = l + formula(l, r, key, array)\n        if array[m] == key:\n            return m\n        elif array[m] < key:\n            l = m + 1\n        else:\n            r = m - 1\n    return -1\n```\n\n## 复杂度分析\n\n插值查找的平均复杂度为 Θ(log log n)，但证明过程相当的复杂，这篇[论文](http://www.cs.technion.ac.il/~itai/publications/Algorithms/p550-perl.pdf)给出了详细的证明过程，感兴趣的同学可以自己去看看，这里我们就不再讨论了。\n\n要是数组不是均匀分布的，插值查找的复杂度会退化到线性的复杂度 Θ(n)。举一个极端的例子，假设数组为 [0, 99, 100, 100, 100]，我们要查找元素 99。第一轮查找我们计算出索引值为 3，第二轮为 2，第三轮为 1，这样我们查找了三次。推广到含有 n 个元素的数组就需要查找 n - 2 次，所以复杂度就为 Θ(n)。\n\n因此，插值查找的高效性只针对均匀分布的数组，而对于分布不均匀的数组，插值搜索就不再适用了。"},{"title":"二分查找与二叉树","url":"/study/algorithm/decrease-and-conquer/binary-search-tree/","content":"\n## 有序表的查找\n\n我们已经讨论过在一个数组中找到相应元素的算法，我们采用的是最简单，最直接的顺序搜索的方式，即从第一个元素开始，从左往右依次搜索，直到查找到该元素或查找失败。对于复杂度而言，我们也讨论过它的平均复杂度为 Θ(n)。那么还有没有更快的算法呢？这一节我们就来讨论一下吧～\n\n如果一个数组本身是有序的，查找一个元素就类似于在前面提到的[猜数问题](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/)，只是这里查找的元素变成了要猜的数。如果我们从数组的中间位置开始查找，在每轮查找过后，我们只需要在剩下一半的数组中再继续查找，这样以此类推，直到查找到该元素，或查找失败。\n\n下面来举一个具体的例子，假设我们的数组长这样：\n\n![数组](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/array0.png)\n\n下面查找元素 61，经过一轮的搜索过后，待搜索数组的长度变为原来的一半：\n\n![数组](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/array1.png)\n\n然后反复这个过程，最终找到 61：\n\n![数组](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/array2.png)\n\n我们只需要十行左右的代码就能轻松实现：\n\n```\ndef binary_search(array, key):\n    l = 0; r = len(array) - 1\n    while l <= r:\n        m = (l + r) // 2  # 向下取整\n        if key == array[m]:\n            return m\n        elif key < array[m]:\n            r = m - 1\n        else:\n            l = m + 1\n    return -1 \n```\n\n最后来分析一下时间复杂度。我们知道，每次查找操作，问题的规模都变为原来的一半。所以我们可以写出以下递归关系式。\n\n![derivation](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/derivation0.png)\n\n怎样来解这个关系式呢？这里我们不妨设 n = 2<sup>k</sup>，这样关系式就变为了 t(2<sup>k</sup>) = t(2<sup>k-1</sup>) + 1，然后再用回代的方式把它解出来。\n\n![derivation](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/derivation1.png)\n\n最后用 n 替换掉 k，得到复杂度为 Θ(log n)。\n\n## 二叉搜索树\n\n如果像下面这幅图一样，把一个有序数组变为二叉树的结构，然后用中间的元素当做树的根节点，左半部分的中间元素当做根节点的左孩子，右半部分的中间元素当做根节点的右孩子，这样以此类推，树的层数就会越来越多，这样我们就构建好了一颗二叉树。\n\n![conversion](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/conversion.png)\n\n我们可以看到，对于每个节点，左孩子都小于它的父节点，右孩子都大于等于它的父节点。所以我们把这样的二叉树叫做**二叉搜索树**（**binary search tree**）。\n\n如果要搜索二叉树里面的元素（这里我们搜索节点 61），我们首先从根节点开始访问。\n\n![二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/tree0.png)\n\n假如根节点的元素就是我们要找的，那么就直接返回该节点；如果查找的元素比根节点大，我们就查找它的右子树。在这个例子里，61 比 48 要大，所以我们从 48 的右子树中搜索 61，这样问题就变成了从以 73 为根节点的二叉树中查找 61 这个元素。\n\n![二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/tree1.png)\n\n同理，如果查找的元素比根节点小，我们就查找它的左子树，这里 61 比 73 要小，所以问题又减小为了从以 61 为根节点的二叉树中查找 61 这个元素。\n\n![二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/tree2.png)\n\n这个过程，我们用递归就能够轻松地实现。在这之前，我们先要构建 `Node` 类和 `BST` 类：\n\n```\nclass Node(object):\n    def __init__(self, value):\n        self.value = value\n        self.left = None\n        self.right = None\n```\n\n```\nclass BST(object):\n    def __init__(self):\n        self.root = None\n```\n\n然后用两个函数来实现：\n\n```\ndef search(self, value):\n    # 树的根节点为空就抛出异常\n    if not self.root:\n        raise ValueError(\"The tree is null\")\n    return self.search_node(self.root, value)\ndef search_node(self, root, value):\n    if not root:  # 如节点为空，则返回 None\n        return None\n    if value < root.value:  # 从左子树查找\n        return self.search_node(root.left, value)\n    elif value > root.value:  # 从右子树查找\n        return self.search_node(root.right, value)\n    else:\n        return root\n```\n\n除了搜索，二叉树还有插入和删除节点的操作。\n\n对于插入节点，我们首先要进行的操作是先找到插入的位置，即通过搜索操作找到插入位点。举一个例子，如果要插入节点 42，首先我们要先找到插入的位置（节点 34），因为 42 比 34 要大，所以 42 作为 34 的右节点。\n\n![二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/insert.gif)\n\n代码实现：\n\n```\ndef insert(self, value):\n    new_node = Node(value)  # 创建一个新节点\n    # 查看根节点是否为空\n    if not self.root:\n        self.root = new_node\n    else:\n        self.insert_node(self.root, new_node)\ndef insert_node(self, root, node):\n    if node.value < root.value:\n        if root.left:  # 从左子树查找\n            self.insert_node(root.left, node)\n        else:\n            root.left = node\n    else:\n        if root.right:  # 从右子树查找\n            self.insert_node(root.right, node)\n        else:\n            root.right = node\n```\n\n删除节点相对来说就要复杂一些，除了要找到删除的节点之外，我们还要对不同情况的节点执行不同的操作。\n\n- 情况 1：删除的为叶子节点\n\n    这种情况最简单，只需要找到该节点，然后删除即可，例如删除这里的 10。\n    \n![二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/delete1.gif)\n    \n- 情况 2：删除的节点只有左孩子或只有右孩子\n\n    这种情况下，只需要将原本指向它的节点指向它的子节点即可。像下面这幅图这样，我们要删除 34 这个节点，这时我们只需要将节点 25 的右孩子指向 34 的右孩子（节点 42）即可，最后删除掉节点 34 。\n    \n![二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/delete2.gif)\n    \n- 情况 3：删除的节点既有左孩子又有右孩子\n\n    这种情况是最麻烦的，删除节点后，要想保持原有二叉搜索树的性质，我们首先要从待删除节点的左子树中找到最大的节点，或者从右子树中找到最小的节点。这里以左子树为例，假设我们要删除节点 48，首先从它的左子树中找到最大节点 42，然后交换它们的值，这样 42 就成为了根节点，原先的 42 变为了这里的 48，最后我们删除节点 48。\n    \n![二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/delete3.gif)\n\n代码实现：\n\n`max` 函数\n\n```\ndef max(self, root):\n    if root.right:\n        return self.max(root.right)\n    return root\n```\n\n```\ndef remove(self, value):\n    # 根节点为空抛出异常\n    if not self.root:  \n        raise ValueError(\"树为空树\")\n    self.root = self.remove_node(self.root, value)\ndef remove_node(self, root, value):\n    if not root:\n        return None\n    # 查找\n    if value < root.value:\n        root.left = self.remove_node(root.left, value)\n    elif value > root.value:\n        root.right = self.remove_node(root.right, value)\n    else:\n        # 左右孩子为空\n        if not root.left and not root.right:\n            del root\n            return None\n        # 只有左孩子或右孩子\n        elif not root.left:\n            temp = root.right\n            del root\n            return temp\n        elif not root.right:\n            temp = root.left\n            del root\n            return temp\n        # 左右孩子都有\n        else:\n            temp = self.max(root.left)  # 找到待删除节点的左子树的最大节点\n            root.value = temp.value\n            root.left = self.remove_node(root.left, temp.value)\n    return root\n```\n\n二叉搜索树的复杂度取决于二叉树的结构。如果像上面的例子那样，复杂度就跟二分查找一样，为 Θ(log n)。假设二叉树长得像下面这张图的右边的树一样，我们会觉得它显得特别地不“平衡”，跟普通的链表没有什么区别，所以复杂度就退化为线性的复杂度 Θ(n)。\n\n![对比](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/images/comparison.png)\n\n因此，二叉树的平衡性显得就尤为重要，后面讲到的[AVL树](https://infinityglow.github.io/study/algorithm/transform-and-conquer/AVL-tree/)和[红黑树](https://infinityglow.github.io/study/algorithm/transform-and-conquer/R&B-tree/)会采用各自的机理，使树尽可能变得“平衡”。"},{"title":"拓扑排序","url":"/study/algorithm/decrease-and-conquer/topo-sorting/","content":"\n##  定义\n\n在大学里，每当到了期末的时候，你一定会头疼于各种选课给你带来的困扰。其中一项就是先修课，每次你高高兴兴地选了自己心仪的选修课，却发现自己不满足先修课的要求，只好默默地退掉。这一次，我们就来讨论一下这个问题。\n\n![选课](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/topo-sorting/images/enrol.jpg)\n\n假设大学里开设了这些课程：高等数学，线性代数，概率论，数据结构，机器学习和计算机视觉。它们存在这样的先修关系：线性代数的先修课为高等数学；概率论的先修课是线性代数；机器学习的先修课为线性代数、概率论和数据结构；最后计算机视觉的先修课是机器学习。\n\n下面我们需要把这些课程和关系做一个抽象化的处理，说白了就是能够让计算机读懂这些关系。这里我们用到了图这种数据结构，把每门课程当做图的节点，两门课的先修关系抽象为图的边，并且还是有向边。要是把它画出来就是这样子的：\n\n![图](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/topo-sorting/images/graph0.png)\n\n这里，我们对上图进行类似“排序”的操作，也就是怎样安排这些课程而不会因为没有修满先修课而不能选上，我们把这种操作叫做**拓扑排序**（**topological sorting**）。\n\n## 卡恩算法\n\n下面就是来解决这个问题了，它跟我们前面提到的减治有什么关系呢？假如我们要在某一个学期修计算机视觉这门课，我们首先要保证修了机器学习这门课，而要达到修机器学习这门课的条件，我们又要修三门前置课，这样问题的规模在逐渐减小，直到这门课没有任何先修条件，也就是我们可以在最开始选择的课。\n\n卡恩算法为我们提供了具体的步骤。\n\n- 步骤 1：在图中找到没有被其它节点所指向的节点，即入度（在图论中，入度指的是所有进入该节点的节点个数）为 0 的节点。\n\n![图](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/topo-sorting/images/graph1.png)\n\n- 步骤 2：删除该节点以及对应的边。\n\n![图](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/topo-sorting/images/graph2.png)\n\n- 步骤 3：重复步骤 1 和步骤 2，直到图中没有入度为 0 的节点。\n\n![图](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/topo-sorting/images/graph-demo.gif)\n\n最后我们用代码来实现一下：\n\n首先还是构建 Vertex 类：\n\n```\nclass Vertex(object):\n    def __init__(self, value):\n        self.value = value\n```\n\n然后找到入度为 0 的节点：\n\n```\ndef find_source(G):\n    source = None\n    V = G.keys(); E = G.values()\n    for v in V:\n        for neighbour in E:\n            for vertex in neighbour:\n                # 检查每条边\n                if vertex is v:\n                    break\n            else:\n                continue\n            break\n        else:\n            source = v\n            break\n    return source\n```\n\n最后是我们的主函数：\n\n```\ndef topo_main(G):\n    order = []\n    while len(G) != 0:\n        s = find_source(G)\n        if s is None:\n            return \"不存在拓扑排序.\"\n        order.append(s.value)\n        G.pop(s)\n    return order\n```\n\n在主程序中，我们先构建一个图 `G`，然后执行 `topo_main` 函数，最后得到排序后的结果：\n\n```\n>>> print(topo_main(G))\n>>> 排序结果为 [\"高等数学\", \"线性代数\", \"概率论\", \"数据结构\", \"机器学习\", \"计算机视觉\"]\n```\n\n其实，除了卡恩算法之外，我们还可以用 DFS 的方法。由于它跟减治的关系不是很大，这里就不做深入的讨论了，感兴趣的同学可以去[网上](https://www.geeksforgeeks.org/topological-sorting/)搜一搜这方面的内容。\n\n"},{"title":"插入排序","url":"/study/algorithm/decrease-and-conquer/insertion-sort/","content":"\n## 减治\n\n在这一章里面，我们会讨论一种解决问题的新方案。**减治**（**decrease and conquer**），全称叫做减而治之，是通过逐步缩小问题规模的方式来解决一个问题。可能你还不是很明白，别急，我们先上一个例子：假设 9 枚金币中有一枚是假的（假币的重量会比真币轻），现在给你一个天平，你需要用最少的次数找出假币，该怎么做呢？\n\n![天平](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/balance.jpg)\n\n你可以一枚一枚地称，但最多你可能要称 8 次才能称出来，不是很高效。其实我们可以将这些金币对半分，即 9 枚金币分为 4 枚和 5 枚。因为天平两边的金币数要是相同的我们才能判断哪边轻，所以这里需要从 5 枚里取出 1 枚。这样如果拿出的那一枚不是假币的话，我们只需要从较轻的 4 枚中找到假币，于是又可以对半分，称量之后，再从其中较轻的两枚中选择。这样以此类推，直到找出假币。\n\n我们可以看到，原问题是从 9 枚金币中找出假币，经过一次称量之后，问题变为了从 4 枚金币中找出假币，再次称量后问题的规模变为了 2，最后变为 1，即找到假币。这就是减治法的精髓了：一个大问题被一次又一次地拆分成了更小的问题，直到我们能够直接解决小问题。\n\n## 插入排序\n\n小时候你一定玩过扑克牌，当你在整理那些乱序的牌的时候，你脑海里想到的第一种方法一定是将这些新摸到的牌插入到对应的位置，以此来达到手牌有序。\n \n![扑克](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/poker.png)\n\n让我们以数组为例，假设有下面的数组：\n\n![数组](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/array0.png)\n\n我们可以看到，前面 3 个元素已经有序，后面 7 个元素还是无序状态，这时候我们需要将第 4 个元素插入到相应的位置，这样有序序列就从 3 增加到 4，无序序列就从 7 减小到 6。\n\n![数组](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/array1.png)\n\n如果对于一个含有 n 个元素的完全无序的数组，我们可以把第一个元素视作有序，其余 n - 1 个元素视为无序，因为只有一个元素的数组肯定是有序的，所以每次将无序序列的第一个元素插入到相应位置后，问题的规模就减少 1。这样我们重复 n - 1 次，数组就从无序变为有序了。\n\n最后我们用代码实现一下插入排序。\n\n```\ndef insertion_sort(array):\n    for i in range(1, len(array)):\n        v = array[i]\n        j = i - 1\n        while j >= 0 and array[j] > v:\n            array[j+1] = array[j]  # 用前一个元素覆盖当前元素\n            j = j - 1\n            cnt += 1\n        array[j+1] = v  # 循环结束后，将 v 插入到相应位置\n    return array\n```\n\n## 复杂度分析\n\n### 最好情况\n\n插入排序的复杂度分析不同于之前讲到冒泡和选择排序，我们需要考虑不同实例下的数组。假设一个数组已经有序，在每次的 `for` 循环里，每个待插入的元素只需要跟自己前面的元素比较后就完成一次插入操作，即每个元素只比较一次。所以，对于一个含有 n 个元素的数组来讲，我们只需要比较 n - 1 次。\n\n![推导](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/derivation0.png)\n\n所以复杂度就为 Θ(n)。我们用一个动画来直观地感受一下。\n\n![demo](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/insertion-best.gif)\n\n### 最坏情况\n\n如果数组是倒序排列的，那么每次待插入的元素都要插入到第一个位置（假设数组每个元素是唯一的）。也就是说，`for` 循环每执行一次，需要比较的次数就为 `i` 次，所以根据这个关系我们可以得出下面的式子：\n\n![推导](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/derivation1.png)\n\n复杂度为 Θ(n<sup>2</sup>)，从动画时间的长短我们就可以看出，这种情况下算法的效率是比较低的。\n\n![demo](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/insertion-avg.gif)\n\n### 平均情况\n\n平均情况的复杂度分析相对来说就要稍微困难一点了，这里我们用基于概率的方式计算，对于第 `i` 个元素，它能够插入的位点有 `i` 处，每一处需要比较的次数分别为 1, 2, ..., i。像下面这张图一样：\n\n![数组](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/array2.png)\n\n假设每个位点插入的概率相同，我们就可以得到下面的式子：\n\n![推导](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/derivation2.png)\n\n这说明了对于一个随机数组，第 `i` 个元素插入到相应位置所需要的平均比较次数为 (i+1)/2 次。对于整个数组而言，待插入的元素是从第 2 个开始，一直遍历到 n，所以只要把它们全部加起来，就能得到平均复杂度了。\n\n![推导](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/images/derivation3.png)\n\n我们看到，虽然时间复杂度也为 Θ(n<sup>2</sup>)，但是前面的系数变为了 1/4，说明平均情况的时间开销要低于最坏情况。为了证明这一结论，我在[本节的代码](https://github.com/infinityglow/Algorithm-and-Complexity/tree/master/Decrease%20and%20Conquer/Insertion%20Sort)里分别模拟了最好、最坏和平均情况所需要的比较次数和运行时间。下面给出部分结果：\n\n```\n最好情况：\n    平均比较次数： 9999\n    平均运行时间：0.0024 s\n最坏情况：\n    平均比较次数： 24927061\n    平均运行时间：4.4334 s\n平均情况：\n    平均比较次数： 49999962\n    平均运行时间：8.6132 s\n```\n\n从上面的结果来看，不论是比较次数还是运行时间，最好情况都要远远优于后面两种情况。所以如果数组是有序的或几乎有序的，采用插入排序会大大降低排序的时间，甚至比后面要讲到的排序算法还要快。\n\n"},{"title":"暴力搜索","url":"/study/algorithm/brute-force/exhaustive-search/","content":"\n## 回顾\n\n在[图的遍历](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/)那一节里面我们知道，不管是深度优先遍历还是广度优先遍历，本质上都是对图中的每一个节点执行一次遍历算法，即穷尽所有的情况。这次要讲到的**暴力搜索**（**exhaustive search**）就是专门为了解决这类问题而产生的。除了图的遍历，暴力搜索还以解决[组合问题](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/)为主。下面我们一起来看看吧～\n\n## 背包问题\n\n背包问题是一道典型的组合问题，问题可以这样来描述它：给定一些物品，这些物品都有它自己的重量 w<sub>i</sub> 和价格 v<sub>i</sub> ，并且每个物品只能选择一次。现在有一个能装 W 重量的背包，你需要尽可能多的使背包内物品的价格最大。\n\n![背包问题](https://infinityglow.github.io/study/algorithm/brute-force/exhaustive-search/images/knapsack.png)\n\n暴力搜索的方式就是将这个问题的全部组合一一列举出来，即穷举集合 {w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>i</sub>, ..., w<sub>n</sub> } 中所有的子集，然后判断重量是否超过了背包上限，如果没有，就分别计算它们的价格，最后选出最高价格的组合。\n\n下面来举一个具体的例子。假设这里的 W = 10，w<sub>1</sub> = 7, v<sub>1</sub> = 42; w<sub>2</sub> = 3, v<sub>2</sub> = 12; w<sub>3</sub> = 4, v<sub>3</sub> = 40; w<sub>4</sub> = 5, v<sub>4</sub> = 25。那么我们根据实例，列举出所有的情况：\n\n| 子集 | 总重量 | 总价格 |\n| :----: | :----: | :----: |\n| ∅ | 0 | 0 |\n| {1} | 7 | 42 |\n| {2} | 3 | 12 |\n| {3} | 4 | 40 |\n| {4} | 5 | 25 |\n| {1, 2} | 10 | 54 |\n| {1, 3} | 11 | 不符合要求 |\n| {1, 4} | 12 | 不符合要求 |\n| {2, 3} | 7 | 52 |\n| {2, 4} | 8 | 37 |\n| {3, 4} | 9 | 65 |\n| {1, 2, 3} | 14 | 不符合要求 |\n| {1, 2, 4} | 15 | 不符合要求 |\n| {1, 3, 4} | 16 | 不符合要求 |\n| {2, 3, 4} | 12 | 不符合要求 |\n| {1, 2, 3, 4} | 19 | 不符合要求 |\n\n总共有 2<sup>4</sup> = 16 种情况，如果我们取出那些符合要求的情况，选择价格最大的一种，问题就解决了，最后的结果为：{w<sub>3</sub>, w<sub>4</sub>} 这种组合，其价格为 65。\n\n如果要写成代码，我们首先要构建一个从集合 {w<sub>1</sub>, w<sub>2</sub>, w<sub>3</sub>, w<sub>4</sub>} 中产生超集（集合的全部子集所构成的集合）的函数 `power_set_gen`。\n\n```\ndef power_set_gen(w):\n    p_set = [set()]\n    for item in w:\n        temp_set = []\n        for subset in p_set:\n            subset = subset | {item}  # 将新元素加入到原有的子集中\n            temp_set.append(subset)\n        p_set.extend(temp_set)\n    return p_set\n```\n\n构建好超集后，就可以在 `knapsack` 函数里面枚举所有的情况啦。\n\n```\ndef knapsack(w_v, p_set, W):\n    w_combination = None; max_value = 0  # 分别用来记录最优情况的组合和最大值\n    for instance in p_set:\n        weight, value = 0, 0  # 累加器\n        for item in instance:\n            weight += item; value += w_v[item]\n        if weight <= W and value > max_value:\n            w_combination = instance\n            max_value = value\n    return w_combination, max_value\n```\n\n最后求得的结果跟上面的一模一样。\n\n```\n>>> python knapsack.py \n>>> 最佳组合为物品 3 和物品 4，其价格为 65。\n```\n\n关于复杂度的问题，只要你知道一个含有 n 个元素的集合的子集数为 2<sup>n</sup>，就能轻松得出复杂度为 Θ(2<sup>n</sup>)了。\n\n## 分配问题\n\n分配问题是另一道经典的组合问题，问题的描述为一家公司有 n 名员工，现在有 n 件任务需要分配给这些员工，一件任务只能分配给一名员工，每名员工完成每件任务都有对应的时间，现在要我们来分配这些任务，最后使总时间最短。\n\n![分配问题](https://infinityglow.github.io/study/algorithm/brute-force/exhaustive-search/images/assignment.png)\n\n我们将上面的图用一个表格来表示：\n\n|  | Task 1 | Task 2 | Task 3 | Task 4|   \n| :----: | :----: | :----: | :----: | :----: |\n| Staff 1 | 9 | 2 | 7 | 8 |\n| Staff 2 | 6 | 4 | 3 | 7 |\n| Staff 3 | 5 | 8 | 1 | 8 |\n| Staff 4 | 7 | 6 | 9 | 4 |\n\n下面我们看看具体该如何来分配。任务 1 可以分配给 4 名员工中的任意一位，当任务 1 分配给一名员工之后，任务 2 就只能分配给剩下的 3 名员工中的一位了，然后任务 3 分配给剩下两名中的一位，最后任务 4 交给最后未分配的员工。所以我们可以根据前边的描述，穷尽所有的情况，将最优情况用“暴力”的手段搜索出来。于是我们可以写出相应的代码。\n\n首先需要有一个生成全排列的函数，来指定每个员工对应的任务序号。\n\n```\ndef perm_gen(source):\n    permutation = [[source[0]]]\n    for i in range(1, len(source)):\n        temp = [] \n        for p in permutation:\n            for j in range(len(p), -1, -1):\n                p.insert(j, source[i])\n                temp.append(p.copy())\n                p.pop(j)\n        permutation = temp.copy()\n    return permutation\n```\n\n```\n>>> print(perm_gen([1, 2, 3]))\n>>> [[1, 2, 3], [1, 3, 2], [3, 1, 2], [2, 1, 3], [2, 3, 1], [3, 2, 1]]\n```\n\n然后是我们的主函数：\n\n```\ndef assignment_bf(perm, table):\n    combination = None; min_cost = np.inf  # 分别用来记录最有情况的组合和最小值\n    for i in range(len(perm)):\n        temp_cost = 0  # 累加器\n        for j, k in enumerate(perm[i]):\n            temp_cost += table[j][k-1]\n        if temp_cost < min_cost:\n            combination = perm[i]\n            min_cost = temp_cost\n    return combination, min_cost\n```\n\n最后输出结果。\n\n```\n>>> python assignment.py\n>>> 最佳分配方案为：\n>>> 员工 1 做任务 2，员工 2 做任务 1，员工 3 做任务 3，员工 1 做任务 4。\n>>> 最短时间为 13\n```\n\n如果我们把上面问题的规模扩大到 n，按照上面的方式，我们就很容易得出一共有 n! 种情况，所以暴力求解分配问题的复杂度自然就为 Θ(n!) 了。\n\n我们可以看到，用暴力搜索的方式解决这两类问题，复杂度分别达到了指数级和阶乘级。要知道，就算当问题的规模很小（n = 20）时，计算机都不能在有限的时间内将它们计算出来，尤其是阶乘级的复杂度，因为 20! 就已经达到了 2.4 × 10<sup>18</sup> 这么大，更何况在现实中，n 都是 10<sup>6</sup> 起步的。所以，用暴力搜索解决组合问题显然是不切实际的。后面的[动态规划](https://infinityglow.github.io/study/algorithm/dynamic-programming/knapsack-problem/)和[匈牙利算法](https://infinityglow.github.io/study/algorithm/hungarian-algorithm/)会给出更为优质的算法来解决这类问题。"},{"title":"最近点对与凸包问题（BF）","url":"/study/algorithm/brute-force/clo-pair-con-hull/","content":"\n## 最近点对问题\n\n这一节内容，我们来看看两个经典的几何学问题。首先是**最近点对问题**（**closest-pair problem**）。问题的描述是在一个二维平面上有一些随机分布的散点，要求我们在这些散点里找到两个点，使得它们的距离最小。\n\n![最近点对](https://infinityglow.github.io/study/algorithm/brute-force/clo-pair-con-hull/images/clo-pair0.png)\n\n有解决这个问题很简单，只需要把所有的情况都列举出来，即每一个点与其他所有节点的距离都计算出来，然后取最小的值。所以，这里我们再次用到了暴力求解的方法。\n\n```\ndef closest_pair_bf(X, Y):\n    d = np.inf  # 初始化 d 为无穷\n    for i in range(len(X)-1):\n        for j in range(i+1, len(X)):\n            d = min((X[i] - X[j])**2 + (Y[i] - Y[j])**2)\n    return d\n```\n\n其中参数 `X` 和 `Y` 分别表示所有散点的横纵坐标的集合。在主程序中，我们用 [`numpy.random.normal`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.normal.html) 方法生成随机数，并且用[`np.column_stack`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.column_stack.html)方法将它们打包。\n\n```\nnp.random.seed(13)  # 为了代码的可复现性\nX = np.random.normal(2, 0.5, size=[16, 1])\nY = np.random.normal(2, 0.5, size=[16, 1])\nXY_pair = np.column_stack((X, Y))\n```\n\n如果平面上有 n 个点，那么要考虑的点对数就为 n(n-1)/2。比如这里一共有 16 个点，我们就要考虑 120 种情况。\n\n![最近点对](https://infinityglow.github.io/study/algorithm/brute-force/clo-pair-con-hull/images/clo-pair1.png)\n\n关于算法的复杂度，我们很容易就能推导得出为 Θ(n<sup>2</sup>)。最后我们标注出最近点对在图中的位置。\n\n![最近点对](https://infinityglow.github.io/study/algorithm/brute-force/clo-pair-con-hull/images/clo-pair2.png)\n\n## 凸包问题\n\n**凸包问题**（**convex-hull problem**）是这里要讨论的第二个问题。首先我们先要弄明白什么是凸包，在生活中，你一定见过在一个扎满钉子的木头上套上一圈橡皮筋的场景，像下面这张图那样。哈哈，实际上在这里橡皮筋围成的多边形就是一个凸包了。\n\n![橡皮筋](https://infinityglow.github.io/study/algorithm/brute-force/clo-pair-con-hull/images/rubber.png)\n\n从严格意义上来讲，凸包指的是由数个点构成的凸多边形（每个内角都小于180度），并且这个多边形能够把这个平面上所有的点都囊括在内。就像上面那张图中被橡皮筋围住的钉子一样。所以，我们怎么来解决这个问题呢？答案当然还是采用最“暴力”的手段。穷举所有的情况，找到我们所需要的多边形。\n\n从形成的凸包多边形我们可以观察到，对于多边形的边所形成的直线，其他所有的节点都在这条直线的同一侧。于是我们可以根据这个特点写出代码：\n\n```\ndef convex_hull_bf(XY_pair):\n    pairs = []  # 用于存储满足条件的点\n    for i in range(len(XY_pair) - 1):\n        for j in range(i+1, len(XY_pair)):\n            a = XY_pair[j][1] - XY_pair[i][1]\n            b = XY_pair[i][0] - XY_pair[j][0]\n            c = XY_pair[i][0] * XY_pair[j][1] - XY_pair[i][1] * XY_pair[j][0]\n            k = 0; pos = 0; neg = 0  # pos 和 neg 用于统计直线左右两侧点的个数          \n            while k < len(XY_pair):\n                if k != i and k != j:\n                    if a * XY_pair[k][0] + b * XY_pair[k][1] - c > 0:\n                        pos += 1\n                    else:\n                        neg += 1\n                    if pos != 0 and neg != 0:\n                        break\n                k += 1\n            else:\n                pairs.append((XY_pair[i], XY_pair[j]))\n    return pairs\n```\n\n对于判断一个点是在一条直线的左侧还是右侧，我们会用到了下面的公式：\n\n![公式](https://infinityglow.github.io/study/algorithm/brute-force/clo-pair-con-hull/images/formula.png)\n\n其中 a = y<sub>2</sub> - y<sub>1</sub>, b = x<sub>1</sub> - x<sub>2</sub>, c = x<sub>1</sub>y<sub>2</sub> - y<sub>1</sub>x<sub>2</sub>，x 和 y 分别为需代入的点。如果值大于 0，那么该点在直线的左侧；如果小于 0，那么该点在直线的右侧。\n\n最后我们将满足条件的点通过收尾相连的方式显示出来，这样我们就能画出多边形了。\n\n![凸包](https://infinityglow.github.io/study/algorithm/brute-force/clo-pair-con-hull/images/con-hull.png)\n\n作图的代码如下：\n\n```\ndef plotting(xy_pair, polygon):\n    plt.scatter(xy_pair[:, 0], xy_pair[:, 1], s=15)\n    for i in range(len(polygon)):\n        np_point_stack = np.stack(polygon[i], axis=1)  # 将每一个点对打包成 (xi, yi) 的形式\n        plt.plot(np_point_stack[0], np_point_stack[1], c='r')\n    plt.show()\n```\n\n最后来分析一下复杂度。我们知道，如果平面上有 n 个点，那么一共就有 n(n-1)/2 个点对，也就是直线的条数。对于每一条直线，又要从剩下 n - 2 个点中判断是否在直线的同一侧。这样一来，只要我们列出求和公式，再经过推导就能够得到复杂度为 Θ(n<sup>3</sup>)。这里我就偷个懒，不详细写出来了～\n\n## 总结\n\n我们可以看到，用暴力求解的办法解决几何问题依然是那么简单、直接，但效率也是依然的低。所以这两种算法也只能解决小规模的问题。面对 n > 10<sup>6</sup> 这种大规模的问题时，我们就要求救[其他算法](https://infinityglow.github.io/study/algorithm/divide-and-conquer/clo-pair-con-hull/)了。\n\n\n\n"},{"title":"图的两种遍历","url":"/study/algorithm/brute-force/graph-traversal/","content":"\n## 邻接矩阵和邻接表\n\n在讲[数据结构](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/)的那一节里我们提到了图这种数据结构，并且介绍了两种表示方法：邻接矩阵和邻接表。接下来我们来分别看看这两种方法是如何表示一张图的吧。\n\n和树这种数据结构不同，图的节点之间的连接是自由的，即一个节点可以连接其他任意节点（包括自身），并且是具有方向性的。所以我们可以根据这样的特性，用 0 和 1 来表示一个节点 u 是否能够到达另一个节点 v。假设一个图由 n 个节点组成，那么我们就有 n<sup>2</sup> 种可能的连接。为了方便，我们用一个 n × n 的矩阵来表示：\n\n![邻接矩阵](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/matrix.png)\n\n根据上面的矩阵，我们可以得知节点 a 可以到达节点 c，而节点 d 却不能到达节点 c。如果我们考虑矩阵中的每一项，根据其连接关系，我们就可以画出这个图：\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph0.png)\n\n如果我们用一个链表的形式来表示一个节点到与之相连的节点，那么我们就可以得到一个由多个链表构成的数组。举个例子，上面的图中，节点 b 对应的链表中含有节点 c 和 f，所以节点 b 是可以直接到达节点 c 和节点 f 的。同样，由于我们的图是一个无向图，所以节点 c 和节点 f 分别对应的链表也是含有节点 b 的。根据整个邻接表，我们也可以画出和上面相同的图。\n\n![邻接表](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/list.png)\n\n## 深度优先遍历\n\n在了解两种遍历算法之前，我们先要知道什么是遍历？**遍历**（**traversal**）是对树（图）这种相对复杂的数据结构中的每一个节点进行逐一访问的过程。换句话说就是我们能够找到一条路，将所有节点都“走”过一遍。\n\n**深度优先遍历**（**depth-first search**）是图的一种遍历方式。既然是深度优先遍历当然是跟深度有关系啦。具体过程：假设从一个节点出发，我们需要尽可能远地探索其他分支，直到遇到“**死胡同**”（**dead end**）。例如下面的图，我们从节点 a 开始遍历，由于算法是尽可能远地探索那些节点，所以当我们探索到“死胡同”的时候，走过的节点就为 a-b-d-e (分支节点按照字母表顺序进行优先选择)。\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph1.png)\n\n节点 e 被遍历后，我们需要退回到节点 d，再尽可能地往更远的地方走，直到再次遇到“死胡同”。所以节点 c 和节点 f 是下一次被遍历的两个节点。\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph2.png)\n\n然后重复这个过程，直到退回到了节点 a。显然，这个过程需要用递归或者栈来实现的（因为后来的节点先离开），要实现这个代码，首先我们先要用一个类来表示图中的节点。\n\n```\nclass Vertex(object):\n    def __init__(self, value, visited):\n        self.value = value\n        self.visited = False\n        self.neighbours = []  # 记录所有与之相邻的节点\n```\n\n然后实现一下深度优先遍历的过程：\n\n```\ndef dfs(v):\n    v.visited = True\n    for w in v.neighbours:\n        if not w.visited:\n            w.visited = True\n            dfs(w)\n```\n\n我们看到，由于节点 g 和节点 h 没有与左边的图连通，所以我们需要再构建一个函数用来遍历所有节点是否被访问过，如果没有，我们就从该节点开始再进行遍历。\n\n```\ndef DFS(G):\n    V = G.keys()\n    for v in V:\n        if not v.visited:\n            dfs(v)\n```\n\n最后我们遍历完全部的节点。\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph3.png)\n\n## 广度优先遍历\n\n和深度优先遍历一样，**广度优先遍历**（**breadth-first search**）也是从一个节点出发，遍历所有节点。但不一样的是，我们这次是尽可能广地遍历其他邻近的节点。还是拿刚刚的图来做例子，当节点 a 被访问后，节点 b 和节点 c 会紧接着被访问。\n\n此时节点 a 的所有邻近节点全部被访问了，所以这里只需要考虑节点 b 和节点 c 的邻近节点，因此下一次被访问的节点就会有 d 和 f，然后我们反复这个过程，最终遍历全部节点。\n\n这种先进来的节点先离开的形式我们可以用一个队列来实现：\n\n```\ndef bfs(v):\n    v.visted = True\n    queue = []  # 初始化一个空队列\n    queue.append(v)  # v 入队\n    while queue:\n        for w in v.neighbours:\n            if not w.visited:\n                w.visited = True\n                queue.append(w)\n        queue.pop(0)  # v 出队\n```\n\n同样，对于那些没有相互连接的图，我们处理的方式是一样的：\n\n```\ndef BFS(G):\n    V = G.keys()\n    for v in V:\n        if not v.visited:\n            bfs(v)\n```\n\n完整的图解如下：\n\n节点 a 入队\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph4.png)\n\n节点 b, c 入队，节点 a 出队\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph5.png)\n\n节点 d, f 入队，节点 b, c 出队\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph6.png)\n\n节点 e 入队，节点 d, f 出队\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph7.png)\n\n节点 g 入队\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph8.png)\n\n节点 h 入队，节点 g 出队。再经过一次 `while` 循环后节点 h 出队，最后遍历完成。\n\n![图](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/images/graph9.png)\n\n那么图的遍历跟暴力求解有什么关系呢？事实上，不管是深度优先遍历还是广度优先遍历，我们可以发现，其实每一个节点在被访问的过程中都执行了一次遍历算法，我们正是通过这种方式，才保证了图的每一个节点能够被访问，达到遍历的效果。后面我们讲到的[暴力搜索](https://infinityglow.github.io/study/algorithm/brute-force/exhausitive-search/)也是运用到了这么一点性质。\n\n图的复杂度怎么计算呢？我们知道图可以由邻接矩阵或邻接表来表示，所以我们要分别来讨论：\n\n如果我们用邻接矩阵来表示，在执行遍历算法的过程中，由于每个节点都要查看其他节点是否与自己相连，即矩阵中每一行的 0 和 1，所以对于一个有 |V| 个节点的图来讲，就要查看 |V|<sup>2</sup> 次，所以用邻接矩阵来表示的图，其两种遍历的复杂度均为 Θ(|V|<sup>2</sup>)。\n\n邻接表由于只记录了每个节点和与之相连节点的信息，即每条边的信息。所以在遍历的过程中，我们需要 |V| + |E| 次，其中 |V| 表示判断节点是否已经被访问过的次数，|E| 表示一个图里边的条数（具有两个方向的边算作两次）。所以用邻接表表示的图，其两种遍历的复杂度均为 Θ(|V|+|E|)。\n"},{"title":"字符串匹配","url":"/study/algorithm/brute-force/string-matching/","content":"\n## 回顾\n\n前面我们学习了两种低效的排序算法，这次我们来看看一个关于搜索的问题：**字符串匹配**（**string matching**）。在[算法的问题类型](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/)那一节里面我们提到了这个问题，这好比你在浏览网页或者在看电子书的时候按下“Ctrl+F”键，然后你输入一个单词或一段话，它就在原文中自动帮你找到那些匹配的文字。\n\n![matching](https://infinityglow.github.io/study/algorithm/brute-force/string-matching/images/matching.png)\n\n上图截自[《算法导论》](http://kddlab.zjgsu.edu.cn:7200/students/lipengcheng/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%EF%BC%88%E8%8B%B1%E6%96%87%E7%AC%AC%E4%B8%89%E7%89%88%EF%BC%89.pdf)的某一页，我在我自己的电脑里试了一下，搜索的是单词“algorithm”，几秒钟就全部搜出来了，可以说速度是相当快的，要知道这本书可是有 1000 多页的呀，这得益于一种高效的算法帮我们能够在短时间内完成复杂的工作。\n\n这类问题似乎很简单，但这也是困扰了科学家们多年，直到现在对于这种算法的探究都还没有停止，因为解决这个问题并不难，我们只需要用最“暴力”的办法就可以解决掉它，但要找到一种高效的算法却是难上加难。我们将在[后面](https://infinityglow.github.io/study/algorithm/time-space-tradeoff/string-matching/)的章节里简单介绍它们。\n\n\n\n## 一个例子\n\n这里我们举一个更加有意思的例子。懂一点生物的小伙伴们肯定知道，DNA 探针（一段短的 DNA 序列）在与一段长的 DNA 分子杂交的时候，它们的碱基一定会遵循配对原则，即：A 跟 T 配对，C 跟 G 配对。对于这个问题，我们可以抽象成一个算法问题，也就是从一个含有“ATCG”的字符串中查找一个**模式**（**patten**）字符串，比如“GAATTC”。\n\n如果我们用暴力求解的方式，也就是从字符串的起始位置开始，与模式字符串的第一个字符对齐，进行比对。如果比对成功，就再比较下一个字符，直到全部比对成功。如果失败，模式字符串就向右移动一个单位，再从头与字符串比对，直到超出右边边界。用一张图来描述是这样子的：\n\n![DNA](https://infinityglow.github.io/study/algorithm/brute-force/string-matching/images/DNA.png)\n\n将这个过程写成代码的形式：\n\n```\ndef string_matching_bf(text, pattern):\n    n = len(text); m = len(pattern)\n    for i in range(n-m+1):\n        j = 0  # 用于记录成功配对的字符个数\n        while j < m and pattern[j] == text[i+j]:\n            j += 1\n        if j == m:\n            return i\n    return -1\n```\n\n其中字符串的长度为 `n`，配对字符串长度为 `m`。接下来我们分析一下复杂度。先来看看最好的情况，最好的情况当然就是一次就成功啦，所以只需要比较 m 次，时间复杂度就为 Θ(m)。最坏的的情况就是，每当模式字符串向右移动一个单位，都需要比较 m 次，并且第 m 次的时候配对失败，所以最坏的情况总共需要比较 m(n-m+1) 次，时间复杂度就为 Θ(mn)。\n\n在自然语言中，通常第一个字符比对失败的概率很大，每次模式字符串移动的一个单位时候所需要比较的次数一般接近于 1，所以平均情况可以视为一个线性的复杂度：Θ(n)。\n\n"},{"title":"冒泡排序与选择排序","url":"/study/algorithm/brute-force/bubble-selection-sort/","content":"\n## 暴力求解\n\n从这一章开始，我们就要正式地进入具体的算法问题了。别忘了，我们没有按照类别将这些算法问题分类（排序，搜索等），而是按照不同的解决方法来划分的。在我们还没有了解那些高(ling)深(ren)莫(tou)测(teng)的算法之前，我们先来学习一种最简单、最直接的解决方式：**暴力求解**（**brute-force**）。\n\n![step](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/images/step.jpg)\n\n所谓的暴力求解就是指：根据问题具体的描述直接写出相应的算法，从而忽略我们观察和分析问题的过程。举两个例子，前面提到的扔鸡蛋的问题，假如你从第一层开始一层一层地试，直到试出在哪一层鸡蛋刚好会碎，这种方法就是最简单，最直接的方法，也是你一开始就能够想到的方法。另一个例子就是假设让你猜一个 1-100 之间的整数，每次猜完之后会告诉你大了还是小了，你可能会想到从 1 开始一个一个递增地往上猜，但这样显然是最笨的方法，聪明的你肯定会从两个数的中间开始猜，像这样的方法我们在[后面](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/)还会再次提及。\n\n从两个简单的例子我们似乎可以提前得出结论：暴力求解的效率一定不会很高，但我们可以很方便的 coding。所以，对于一些规模很小的问题我们可以采用这种方式，但对于规模较大的问题，我们计算机的 CPU 可能就吃不消了。\n\n![sick](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/images/sick.jpg)\n\n## 冒泡排序\n\n下面我们就从两种最简单的排序算法开始介绍。首先是**冒泡排序**（**bubble sort**），当你一听到这个名字的时候，你就可能认为它跟冒泡泡有一定关系，事实上的确如此，我们可以先从一个动画（来源于[网络](https://visualgo.net/en/sorting)）直观地感受一下：\n\n![demo](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/images/bubble.gif)\n\n可以看到的是，每次循环，左边总有一些大的数会向右“浮动”到相应的位置，如果把它旋转 90 度，这些数就好像在“冒泡”了。实际上，冒泡排序是基于数组中相邻两个元素的比较，如果乱序就交换位置，一直重复这个过程直到数组有序。因为在每次循环中，那些较大的数总是要跟较小的数做交换，所以在直观上就好像这些较大的数在往右“浮动”了。\n\n冒泡排序的实现非常简单，几行代码就能够搞定：\n\n```\ndef bubble_sort(array):\n    n = len(array)\n    for i in range(n-1):\n        for j in range(n-1-i):\n            if array[j] > array[j+1]:\n                array[j], array[j+1] = array[j+1], array[j]\n    return array\n```\n\n其中 n 为数组的长度。那冒泡排序的效率如何呢？根据我们前面所学的[复杂度分析](https://infinityglow.github.io/study/algorithm/complexity-analysis/non-recursive/)的内容，我们可以得到并推导出下面的式子：\n\n![推导](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/images/derivation0.png)\n\n最后我们推出冒泡排序的复杂度为 Θ(n<sup>2</sup>)。\n\n## 选择排序\n\n**选择排序**（**selection sort**）是用暴力求解来解决排序问题的第二种方法，同样它也是一种简单、直接的方法，让我们先从一个动画（来源于[网络](https://visualgo.net/en/sorting)）演示中来一探究竟吧。\n\n![demo](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/images/selection.gif)\n\n从动画中可以看到，每次循环都会从右边未排序的序列中选择一个最小的数，与未排序的序列中的第一个元素交换，然后反复这个过程，知道循环结束。\n\n选择排序用 Python 实现也很容易，也只需要几行代码：\n\n```\ndef selection_sort(array):\n    n = len(array)\n    for i in range(n-1):\n        min = i\n        for j in range(i+1, n):\n            if array[min] > array[j]:\n                min = j\n            array[i], array[min] = array[min], array[i]\n    return array\n```\n\n因为要暂存那些最小值的索引值，所以这里用到了一个变量`min`。最后来分析一下选择排序的复杂度，跟冒泡排序一样，根据循环结构，可以推导出最终的复杂度也为 Θ(n<sup>2</sup>)\n\n![推导](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/images/derivation1.png)\n\n从时间复杂度我们可以看出，这两种排序算法的效率都不高。为了间接的证明这个结论，我在这一节的[完整代码]()里用到了每次排序所需要的比较次数和排序时间这两个指标来间接反映这一结论。后面我们还会接触到一些更为高效的算法，大家也可以通过这两个指标来判断一个排序算法快慢与否。\n"},{"title":"复杂度分析（递归）","url":"/study/algorithm/complexity-analysis/recursive/","content":"\n## 什么是递归\n\n前面我们对一些算法的复杂度进行了分析，但这些都是基于循环和迭代的，这一节我们会针对递归的算法进行复杂度分析。首先要需要知道什么是递归，**递归**（**recursion**）是函数调用自身的一个过程。举个例子，假设你是一个英语水平有限的人，你在读一段英文材料中遇到了某个生词，你需要查字典去了解这个单词的意思，但是字典只提供了英英字典，意味着你找到的单词下方的释义也有可能是你不认识的单词，于是你又继续查找那些单词的意思，而那些单词的释义有可能又出现你不认识的单词，你又继续查找直到你能够全部看懂为止。这样一个过程我们可以把它看做递归，因为查字典这个动作在不停地调用自身。\n\n![字典](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/dictionary.jpg)\n\n试想如果你的英语水平很糟糕，你可能查了很久的字典还是没有弄明白这个生词是什么意思，甚至出现单词 A 用到了单词 B 做释义，单词 B 用到了单词 A 做释义这种情况，即无限循环。那么一次递归结束的条件是什么呢？显然，如果一个单词的释义你全都能看懂，当前递归就结束了，这种条件叫作**初始条件**（**initial condition**），也叫作递归的出口。\n\n## 阶乘的计算\n\n阶乘的计算大家应该都不陌生，一个数的阶乘 n ! = n × (n-1) × (n-2) × ... × 2 × 1，所以我们自然而然想到的计算方法是从 1 到 n 把它们乘起来，但只要我们稍微观察一下便可以得到 n ! = n × ( n - 1) ! 这样的关系式。这个关系式也不是一直递归下去的，同样需要一个出口，根据定义，0 的阶乘等于 1，所以当 n = 0 时递归停止。我们可以用几行代码轻松地实现它：\n\n```\ndef factorial(n):\n    if n == 0:\n        return 1\n    return n * factorial(n-1)\n```\n\n如果用一个数学关系式是来表达是这样子的：\n\n![关系式](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/relation0.png)\n\n我们观察可以得到这样的规律：问题的规模 n 在经过一次乘法运算 n × F(n - 1) 后变为了 n - 1，并且每经过一次乘法运算，问题的规模都减少了 1，所以要求这个算法的复杂度，我们可以推出如下的关系式：\n\n![关系式](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/relation1.png)\n\n其中“+ 1”代表问题的规模每减少 1 就执行了一次乘法运算。这样的关系式叫作**递归关系式**（**recurrence relation**），要解出这个关系式，我们需要一步一步地推导，具体来讲就是先将 n - 1 代入式子中得到一个新的递归关系式，再将它代入到原式子中就可以得到 t(n) = t(n - 2) + 2，如此往复，直到出现递归出口。\n\n![推导](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/derivation0.png)\n\n于是我们得出计算阶乘的时间复杂度为 O(n)。\n\n## 汉诺塔\n\n汉诺塔大家肯定都玩过，规则也很简单：有 A, B, C 三根柱子，上面穿有从大到小排列的圆盘，现在你需要借助 B 柱把 A 柱上的圆盘挪到 C 柱上，一次只能挪一个，但大的圆盘不能放在小的圆盘之上。\n\n ![演示](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/demo.gif)\n\n那么它跟递归有什么关系呢？如果你是一个细心观察的人，你就会发现，要想把 n 个圆盘从 A 柱挪到 C 柱上，你首先要通过某种方法把 n - 1 个柱子从 A 挪到 B 柱上，给 A 柱上最大的圆盘“腾个位置”出来，然后把最大的圆盘移到 C 柱上，最后在通过某种方法把 B 柱上 n - 1 个圆盘挪到 C 柱上。至于怎么移动这 n - 1 个柱子，我们可以再用某种方法移动 n - 2 个柱子，给第二大的圆盘“腾位置”，再将 n - 2 个柱子移动到相应的柱子上。这样我们便可以一直递归下去，直到只有一个圆盘，也就是这里的递归出口了。\n\n我们用几张图来直观地理解一下，假设这里有 4 个圆盘，我们可以分为三个步骤：\n\n ![状态0](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/state0.png)\n\n- 步骤一：将 3 个圆盘从 A 柱移动到 B 柱\n\n![状态1](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/state1.png)\n\n- 步骤二：将 A 柱剩下的圆盘移动到 C 柱\n\n![状态2](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/state2.png)\n\n- 步骤三：将 3 个圆盘从 B 柱移动到 C 柱\n\n![状态3](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/state3.png)\n\n那么怎样来写递归关系式呢？我们看到，要解决 n 阶汉诺塔的问题，我们先要解决两个 n - 1 阶同样的问题，外加一个单次移动。所以我们的递归关系式应该这样写：\n\n![关系式](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/relation2.png)\n\n我们还是采用回代的方式解出这个关系式：\n\n![推导](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/images/derivation1.png)\n\n复杂度为 O(2<sup>n</sup>)，最后我们用代码来实现一下吧。\n\n```\ndef hanoi(a, b, c, n):\n    if n == 1:\n        print(\"{} -> {}\".format(a, c))\n        return\n    hanoi(a, c, b, n-1)  # c 柱为枢纽，将 a 柱中 n - 1 个圆盘移到 b 柱上\n    hanoi(a, b, c, 1)  # 将待移动的圆盘数设为 1\n    hanoi(b, a, c, n-1)  # a 柱为枢纽，将 b 柱中 n - 1 个圆盘移到 c 柱上\n```\n\n让我们试试 `n = 3` 时输出的结果：\n```\na -> c\na -> b\nc -> b\na -> c\nb -> a\nb -> c\na -> c\n```\n\n类似的例子还有很多，但它们的方法都是一样的。"},{"title":"复杂度分析（非递归）","url":"/study/algorithm/complexity-analysis/non-recursive/","content":"\n## 最好，最坏和平均情况\n\n一个算法的好坏并不是一成不变的，它会在不同的情况下有着不同的表现。先来看看一个生活中的场景，假设买彩票中奖的概率是1 / 10,000，那么在最好，最坏和平均的情况下需要买几注彩票才能够中奖呢？显然，如果你的运气够好，第一注你就直接中了，这是最好的情况；相反，如果你的手气够差，你买的彩票永远都中不了奖，这是最坏的情况；平均来讲，你需要买最少10,000注才能够中奖，其实就是这里的数学期望。\n\n![彩票](https://infinityglow.github.io/study/algorithm/complexity-analysis/non-recursive/images/lottery.jpg)\n\n这里的类比并不是想说明算法跟概率学有任何的关系，只是想告诉大家，算法的复杂度确实是有“运气”的成分，它取决于一个（类）问题的**实例**（**instance**）。这里的实例可以这样来理解：如果排序是我们要解决的问题，也就是对任意无序数组的有序化，那么一个实例就是一个具体的数组，比如 [3, 1, 2, 5, 4] 或 [1, 2, 3, 4, 5]。\n\n我们可以看到，后者的数组已经有序了，不需要再额外执行任何操作。对于有些排序算法来讲就可以利用这一点性质，减少执行的次数，让算法更有“远见”。像这样能使一个算法执行次数最少的情况我们把它称作**最好情况**（**best case**）。相反，使一个算法执行次数最多的情况叫做**最坏情况**（**worst case**）。最后剩下的**平均情况**（**average case**）指的是通常状态下算法的复杂度，它并不是等于（最好情况 + 最坏情况）/ 2 这么简单，而是要把所有的 instance 考虑在内，计算复杂度，然后再求一个平均值，后面的例子会详细讨论这个问题。\n\n## 顺序查找\n\n如果我们要查找数组里的某个元素，我们可以通过顺序查找的方式进行，也就是从左往右依次查找。代码如下：\n\n```\ndef find(array, element):\n    length = len(array)\n    for i in range(length):\n        if array[i] == element:\n            return i\n    return -1\n```\n\n我们用一个`for`循环遍历整个数组，如果找到了`element`就返回相应的索引值，否则返回 -1。判断这一条件是否成立的语句显然是 `if array[i] == element`，并且它是被执行的最多的语句，我们将这种执行次数最多，耗时最长的操作叫做**基本操作**（**basic operation**）。一般这种操作出现在最内层的循环，或者出现[递归](https://infinityglow/study/algorithm/complexity-analysis/recursive/)的地方。\n\n然后，我们来分析一下最好和最坏情况的时间复杂度。首先，最好的情况是循环的第一个元素就是我们要找的，比如我们要从数组 [3, 1, 2, 5, 4] 中找元素 3，那么时间复杂度显然就为 O(1)；最坏的情况是最后一个元素才是我们要找的或者查找失败，比如像这样的数组 [1, 2, 4, 5, 3] 需要执行 5 次基本操作。一般的情况，如果数组的长度为 n，则需要 n - 1 次，所以复杂度为 O(n)。\n\n最后我们来说一说平均复杂度，如果我们考虑了所有的情况，即查找的元素 `element` 在数组 `array` 的每一个位置都会出现，且出现的概率是相等的，那么我们可以通过这样一个式子来计算：\n\n![公式](https://infinityglow.github.io/study/algorithm/complexity-analysis/non-recursive/images/formula0.png)\n\n其中分子项为每一种情况需要查找的次数，最后得到的复杂度也为 O(n)，表明了在一般情况下该算法的时间复杂度也为线性复杂度。\n\n## 矩阵乘法\n\n让我们再来看一个例子，相信学过线性代数的小伙伴对矩阵的乘法应该不陌生，假设有两个矩阵 A (m × n) 和 B (n × p)，最后得到的矩阵 C (m × p) 中每一项都是 A 中每一行的 n 个元素和 B中每一列的 n 个元素乘积之和。下面是一个动图的演示（摘自[3Blue1Brown](https://www.youtube.com/watch?v=XkY2DOUCWMU)里的视频）：\n\n![矩阵乘法](https://infinityglow.github.io/study/algorithm/complexity-analysis/non-recursive/images/matmul.gif)\n\n如果写成 Python 的代码就是这样子的：\n\n```\ndef matmul(A, B):\n    n = len(A)\n    C = [[0 for i in range(n)] for j in range(n)]\n    for i in range(n):\n        for j in range(n):\n            for k in range(n):\n                C[i][j] = C[i][j] + A[i][k] * B[k][j]\n    return C\n```\n\n这里为了计算方便，两个矩阵都采用了方阵的形式。很显然，这里的基本操作是 `C[i][j] + A[i][k] ∗ B[k][j]`。准确地来说，由于在计算机里做乘法比做加法所耗费的时间要大，所以 `A[i][k] ∗ B[k][j]` 才是我们的基本操作。\n\n分析完了基本操作，下面就来计算复杂度了。因为不管什么样的矩阵，它们执行的基本操作都是一样的，所以就不存在最好，最坏和平均情况的讨论了。于是根据循环我们可以得到：\n\n![公式](https://infinityglow.github.io/study/algorithm/complexity-analysis/non-recursive/images/formula1.png)\n\n其复杂度为 O(n<sup>3</sup>)。是不是很简单呢？类似的例子还有很多，但它们方法都是一样的。\n"},{"title":"三种表示方法：O, Ω, Θ","url":"/study/algorithm/complexity-analysis/three-notations/","content":"\n## 引入\n\n前面我们讲到了求最大公约数的算法：欧几里得算法。我们先举一个具体的实例：24 和 16 的公约数。根据其公式 `gcd(m, n) = gcd(n, m mod n)`，我们可以得到：`gcd(24, 16) = gcd(16, 8) = gcd(8, 0)`，所以最大公约数是 8。除了这种方法以外，我们还可以从 16 开始一个一个地递减，如果存在两数都能够被整除，那么这个数就是最大公约数。写成代码的形式就是：\n\n```\ndef gcd(m, n):\n    r = min(m, n)  # 选较小者\n    while r != 0:\n        if m % r == 0 and n % r == 0:\n            return r\n        r -= 1 \n``` \n\n我们可以计算得出，该算法的 if 语句被执行了 9 次，而前面的方法只执行了 3 次，我们看两者出现了差异，换句话说就是算法的效率出现了不同。下面就引出**时间复杂度**（**time complexity**）的概念：当一个问题的规模 n 趋向于无穷大的时候，算法所需要的时间 t(n) 。当然，如果一个算法需要很大的运行空间，那么**空间复杂度**（**space complexity**）就是当 n 趋向于无穷大的时候，算法所需要的空间 s(n) 。\n\n## 用于约束的 O, Ω, Θ\n\n那么问题来了，t(n) 的单位是什么呢？如果是秒的话，不同的计算机，不同的运行环境，计算出的结果肯定是不一样的，难以达到统一，这就需要我们定性的去描述这个问题，所以就有了用另一个函数来约束 t(n)。其中大 O 符号约束了 t(n) 的**上界**（**upper bound**）。换句话说，当 n 在趋近无穷大的时候，t(n) 的大小总是小于等于某个函数。举个例子，前面用迭代法求最大公约数所耗费的时间跟问题的规模明显呈现的是一个线性关系，那么我们可以这样表示：t(n) ∈ O(g(n))，其中 g(n) = n。当然，t(n) 也满足 t(n) ∈ O(n<sup>2</sup>)。这里为了更好的理解，没有采用严格的数学定义，感兴趣的同学可以去[维基百科](https://zh.wikipedia.org/wiki/%E5%A4%A7O%E7%AC%A6%E5%8F%B7)一探究竟，这里我们就不细讲了。\n\n同样，大 Ω 符号约束了 t(n) 的**下界**（**lower bound**），即 n 在趋近无穷大的时候，t(n) 总是大于等于某个函数。还是拿刚才的例子，t(n) 我们可以表示为 t(n) ∈ Ω(n)，代表其时间复杂度不会低于线性的复杂度，当然也不会低于常数的复杂度（不随 n 的变化而变化），所以也有：t(n) ∈ Ω(1)。\n\n剩下的 Θ 符号就代表的是 t(n) 的**确界**（**tight**）了，就是说 n 在趋近无穷大的时候跟它时间复杂度一样的一个函数。所以前面的例子就有：t(n) ∈ Θ(n)。最后用三张图来直观地感受一下吧！\n\n![illustration](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations/images/illustration.png)\n\n## 复杂度的比较\n\n如果给定两个时间复杂度 O(f(n)) 和 O(g(n))，怎样来判断哪个时间复杂度比较大呢？根据复杂度的定义我们知道，一个函数在趋向于无穷大时的变化情况决定了复杂度的大小，而要比较两者的大小，我们可以通过做商的方式，像这样：![limit0](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations/images/limit0.png) 这个极限可能会出现好几种情况，让我们分别来看看吧。\n\n- 情况1 极限为 0\n\n   假设 f(n) = n，g(n) = n<sup>2</sup>。那么我们就可以得出极限为 0 ![limit1](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations/images/limit1.png) 这样我们可以认为 f(n) 的增长慢于 g(n) 的增长，即 f(n) 的复杂度低于 g(n) 的复杂度。\n\n- 情况2 极限为 ∞\n   \n     假设 f(n) = n，g(n) = log n。由于极限是无穷比无穷的未定式，所以我们可以借助洛必达法则，最后得出极限为 ∞ ![limit2](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations/images/limit2.png) 这样我们可以认为 f(n) 的增长快于 g(n) 的增长，即 f(n) 的复杂度高于 g(n) 的复杂度。\n     \n- 情况3 极限为 c\n   \n     假设 f(n) = 3n<sup>2</sup> + 5，g(n) = 7n<sup>2</sup> + log n。同样借助洛必达法则，最后得出极限为一常数 c ![limit3](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations/images/limit3.png) 这样我们可以认为 f(n) 的增长快慢和 g(n) 相同，即 f(n) 的复杂度和 g(n) 的复杂度相同。\n    \n从情况 3 我们可以观察出，两个函数的复杂度都由前面的部分决定（3n 和 7n），这间接地说明了前面的部分占据了主要的地位，于是我们可以把一些常见的复杂度排个序，并用一张图展示出来。\n\n![comparison](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations/images/comparison.png)\n\n从左上到右下，其大小排列依次是：O(2<sup>n</sup>) > O(n<sup>3</sup>) > O(n<sup>2</sup>) > O(nlog n) > O(n) > O(log n) > O(1)\n\n\n"},{"title":"算法的问题类型","url":"/study/algorithm/basic-knowledge/problem-types/","content":"\n## 概述\n\n前面讲到了很多关于数据结构的概念，后面的内容就要用这些数据结构和算法来解决具体的问题了。那么首先我们是不是要对这些问题归一个类呢？废话不多说，直接先列举出来，主要分为五大类：\n\n- 排序问题\n- 搜索问题\n-  图的问题\n-  几何问题\n- 组合问题\n\n## 排序问题\n\n排序问题是计算机科学里最基础，也是最重要的问题，很多情况下直接决定了你设计的程序的效率，因为大部分的程序都会用到排序。在实际生活中排序也是用处多多。一个最简单的例子就是国外大学的招生办将申请者的 GPA 全部导入到 Excel 中，然后将它们从高到低依次排序来筛选他们想要的学生。\n\n排序所要实现的功能也很简单，我们的输入可以是一串无序的数字或者字母，输出就是从大到小或从小到大排列的有序数组，像这样：\n\n![排序](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/images/sorting.png)\n\n## 搜索问题\n\n搜索也是我们无时不刻都会用到的一个功能。Google 和百度的服务器每天都要从互联网上爬取海量的数据，然后将它们放在搜索树中以便于用户的查找。试想，如果这个搜索的效率很低很低，要几十秒甚至是几分钟才搜索出结果，那这两家公司可能也不会有今天的成就了吧。\n\n所以这就是我们要讨论的第二个问题：搜索问题。它可以再分为两个类，一个是用于单一键的搜索，例如下面这颗二叉树，我们要搜索 `Key = 35` 的节点是否存在：\n\n![搜索](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/images/search.png)\n\n第二个问题是关于**字符串匹配**（**string matching**）的。假设我们有一段英文：“A fall into a pit, a gain in your wit.”，现在要从里面查找“pit”这个单词以及它所处的位置。跟第一种不同的是，我们要查找的不再是一个单一的键而是一个字符串。这样就和我们从网页或电子书里搜索一段话没什么区别了。\n\n## 图的问题\n\n图的问题可谓是应用面最广的问题类型之一了。当我们开车迷路时，我们的手机里的高德地图总是给我们规划好距离最短的路线，或是耗时最短的路线，引领着我们到家。再就是小的时候玩过的“一笔画”游戏，其抽象成图的问题就为：给定一些图的节点和边 `<V, E>` ，总是存在一条路径包含了所有的边，且每条边只能被访问一次。下图就分别列举出了存在和不存在的情况。这些通通都要用到图的算法来解决。\n\n![一笔画](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/images/E-path.png)\n\n## 几何问题\n\n几何问题当然就是讨论关于点、线、面的问题啦。这里有一个最经典的问题：邮局选址问题。问题的描述是一条笔直的马路两侧分布着一些村庄，现在要在这些村庄之间修建一个邮局，使得所有村庄离这个邮局的距离之和最短。后面我们还会讨论**最短点对问题**（**closest-pair problem**）和**凸包问题**（**convex-hull problem**）。\n\n![邮局](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/images/post-office.jpg)\n\n## 组合问题\n\n前面提到的“一笔画”问题不仅是关于图的问题，同样它也是一个组合问题，这样的问题试图从排列组合中找到答案。我们知道，排列组合问题的规模一般都非常大，所以组合问题也是算法里面最耗时，最难解决的一类问题。后面我们还会讨论[背包问题](https://infinityglow.github.io/study/algorithm/dynamic-programming/knapsack-problem/)等一系列组合问题。\n\n![背包问题](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/images/knapsack.png)\n\n"},{"title":"基本数据结构","url":"/study/algorithm/basic-knowledge/data-structure/","content":"\n## 概念\n\n如果说程序员是用代码编织这个世界的一群人，那么**数据结构**（**data structure**）就是编织所用到的各种工具了，它将计算机中各种各样的数据组织在一起。而我们的算法就是利用这些现有的工具将它们拼接成风格、功能各不相同的程序了。简单来说：算法 + 数据结构 = 程序。这一节就让我们来了解一些基本的数据结构吧。\n\n## 数组与链表\n\n我们从最简单的一维数据结构开始。数组大家应该都不陌生，它是将一组相同数据类型的数据存储在一起的数据结构。\n\n![数组](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/array0.png)\n\n这里我们分析一下最基本的三大操作：查找、插入和删除。\n\n拿上面的图为例，因为数组中每一个**元素**（**element**）都有自己的一个下标，称为**索引**（**index**），它们被存储在计算机的RAM中，所以查找的速度非常快。一般查找的时间不随数组长度而增加。\n\n插入和删除就要稍微麻烦一些。因为数组占用的是计算机内存的连续地址空间，所以在插入一个新元素时，所有在它后面的元素都要向后移动一个单位，为新元素“腾出”位置。同理，为了保持数组的完整性，删除一个元素后，所有在它后面的元素也要向前移动一个单位，以此来“填充”空位。\n\n以这里的数组为例，如果我们要删除 `index = 5` 的元素，那么在它后面的 `15`，`34` 和 `80` 都要向前移动一个单位，如下图中所示。\n\n![数组](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/array1.png)\n\n让我们用Python代码来实现一下。\n\n```\n# 查找\ndef search(array, element):\n    length = len(array)\n    for i in range(length):\n        if array[i] == element:\n            return i\n    return -1\n\n# 插入\ndef insert(array, idx, element):\n    new_array = array.copy() + [None]  # 复制原数组到一个新数组\n    length = len(new_array); i = length - 1\n    # 所有idx之后的元素向右移动一个单位\n    while i > idx:\n        new_array[i] = new_array[i-1]\n        i -= 1\n    new_array[idx] = element\n    return new_array\n\n# 删除\ndef remove(array, element):\n    length = len(array)\n    idx = search(array, element)  # 找到对应索引\n    if idx != -1:\n        # 如果查找成功，所有在idx之前的元素向左移动一个单位\n        while idx < length - 1:\n            array[idx] = array[idx+1]\n            idx += 1\n        array = array[: -1]\n    return array\n```\n\n再来说一说链表。与数组采取的顺序存储方式不同，链表中所有的元素的存储地址都是分散的，也就是说，它是靠一条链条（指针）把这些元素联系在一起的。所以我们把链表中每一个存储单元称为一个**节点**（**node**），在每个节点里有两个域：一个用来存储数据，一个是指针指向下一个节点，像这样：\n\n![链表](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/linked-list0.png)\n\n在Python中我们用一个类来表示：\n\n```\nclass Node(object):\n    def __init__ (self, value, next):\n        self.value = value\n        self.next = None\n```\n\n如果将它们串联在一起，将会是这样：\n\n![链表](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/linked-list1.png)\n\n其中的`header`指的是头结点，它一般记录第一个节点的地址和链表的长度，我们在查找的时候就是从头结点开始的，代码如下：\n\n```\nclass Linked_List(object):\n    def __init__ (self):\n        self.length = 0\n        self.header = None\n    def search(self, value):\n        p = self.header  # 获取第一个节点\n        while p != None:\n            if p.value == value:\n                return p\n            p = p.next\n        return None\n```\n\n和数组相比，链表的插入和删除就非常的简单，只需要改变一下指针即可。下面还是以插入元素`61`为例：\n\n首先需要新建一个节点p\n\n![链表](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/linked-list2.png)\n\n然后，p的指针指向头结点所指的节点\n\n![链表](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/linked-list3.png)\n \n最后，改变头结点的指针，使其指向p，同时更新链表的长度length。\n\n![链表](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/linked-list4.png)\n\n插入和删除的Python实现：\n\n```\nclass Linked_List(object):\n    def __init__ (self):\n        self.length = 0\n        self.header = None\n    def insert(self, value):\n        # 新建一个节点\n        p = Node(value)\n        p.next = self.header\n        self.header = p\n        self.length += 1\n    def remove(self):\n        p = self.header  # 获取第一个节点\n        if p is not None:\n            self.header = p.next\n            self.length -= 1\n            del p  # 删除节点 p\n```\n\n## ADT\n\n**抽象数据类型**（**Abstract Data Type**, 简称**ADT**）是数据结构中非常重要的一个部分。用最简单的理解方式就是：不仅限于编程语言中已经实现的一些数据类型，例如 Python 中 list，set，tuple，dictionary 等等。我们可以进一步的定义出属于我们自己数据结构，比如说增删只能在一侧进行，具有层状、环状的结构等等。那就让我们来看看几个最为常见的例子吧～\n\n### 栈\n\n**栈**（**stack**）就是前面提到的只能在一侧进行元素的增加和删除的数据结构，这种过程分别称为**入栈**(**push**)和**出栈**(**pop**)。生活中最简单的类比就是叠盘子，新洗好的盘子总是放在最上面，而拿走的时候总是从最上面一个拿走。这种后进先出（**last in, first out**）的方式就体现了这种思想。\n\n![栈](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/stack.jpeg)\n\n### 队列\n\n和栈相反，**队列**（**queue**）是遵循**先进先出**（**first in, first out**）的方式实现元素的增减，其过程分别叫做**入队**（**enqueue**）和**出队**（**dequeue**）。生活中的例子就是去超市收银台排队的时候，排到队伍后面的人要先等前面的人都结完账了自己才能结账，所以这就是先进先出啦。\n\n![队列](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/queue.png)\n\n因为和前面的数组和链表有相似性，所以这里就不再用Python代码做演示了，你可以去我的[GitHub](https://github.com/infinityglow/Algorithm-and-Complexity/tree/master/Basic%20Knowledge/Data%20Structure)主页查看本节的完整代码。\n\n### 树\n\n与前面的数据结构不同，**树**（**tree**）是典型的层状数据结构。直观上来看，它就像倒挂着的一颗树，每一个节点连接着多个子节点。这里为了方便，我们只讨论**二叉树**（**binary tree**），也就是每一个节点最多只有两个子节点的情况。\n\n![树](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/tree0.png)\n\n下面来简单介绍一下二叉树的性质。和所有树状结构一样，二叉树在非空的情况下一定有一个**根节点**（**root node**），如图中的节点26。它的两个子节点我们分别把它们叫做该节点的**左孩子**（**left child**）和**右孩子**（**right child**），而对于那些没有孩子的节点，我们把它称做**叶子节点**（**leaf node**）。前面只是针对节点的讨论，而对于树本身，我们要了解的是满二叉树和完全二叉树。\n\n满二叉树是指每一个节点孩子的个数只能为0或2，如下图所示，左边是一颗满二叉树，但右边由于节点48只有一个孩子，所以就不是满二叉树。\n\n![树](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/tree1.png)\n\n再来看完全二叉树，它的性质是除了最后一层的节点没有排满以外，其他层的节点均已排满，并且最后一层节点都是从左往右依次排列。下图的两个例子分别代表了完全二叉树和非完全二叉树。后面的[堆](https://infinityglow.github.io/study/algorithm/transform-and-conquer/heap/)也会用到这种性质。\n\n![树](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/tree2.png)\n\n在Python中我们可以用一个类来表示树的节点：\n\n```\nclass Node(object):\n    def __init__ (self, value):\n        self.value = value\n        self.left = None  # 左孩子\n        self.right = None  # 右孩子\n```\n\n### 图\n\n**图**（**graph**）是 ADT 中用到的最多的结构，生活中的方方面面都会用到图。例如，高德地图就是把所有城市，所有道路通通抽象成了图这种数据结构来帮助我们导航的。哈哈，厉害吧！那我们就首先来了解一下图的基本结构。\n\n图也是由一个一个的**节点**（**vertex**）组成的。但与树不同的是，图的节点之间相连的叫做**边**（**edge**），所以我们用 G = <V, E> 来表示一张图，其中的 V 表示由 vertex 构成的集合，而 E 则表示由 edge 构成的集合。\n\n图的分类一般有好几种，如果一个节点到另一个节点是双向的我们把它叫做**无向图**（**undirected graph**），如果是单向的就叫**有向图**（**undirected graph**），下图中就分别代表了无向图和有向图。\n\n![图](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/graph0.png)\n\n假如从一个节点到另一个节点是要付出“代价”的，那么我们就可以在每一条边上把这种“代价”体现出来，称之为**权重**（**weight**），而构成这样的图当然就叫做**有权图**（**weighted graph**）了。\n\n![图](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/graph1.png)\n\n我们可以用两种方式来表示一张图，一种叫做**邻接矩阵**（**adjacency matrix**）和**邻接表**（**adjacency list**），后面的内容会详细讨论，先上图。\n\n![图](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/images/graph2.png)\n\n这样我们就完成所有基本数据结构的学习了，是不是对它们有了清晰的认识呢？\n\n[本节全部代码](https://github.com/infinityglow/Algorithm-and-Complexity/tree/master/Basic%20Knowledge/Data%20Structure)\n"},{"title":"算法与复杂度","url":"/study/algorithm/overview/","content":"\n## 前言\n\n这个系列的博文会逐个介绍计算机科学里面最基础、也是最重要的一部分内容：**算法**(**algorithm**)。提到它，这可能是你最擅长的部分，亦或是你学生生涯的噩梦。不管怎么样，对于学计算机的小伙伴来讲，它始终是不可回避的一个话题。不论是学生时代的你还是已经踏上了工作的岗位，算法都会一直陪伴着你。\n\n为什么要做这个系列呢？因为网上对于这一块的内容实在是太多，甚至是太杂，而很少有把算法的知识体系整合起来形成一个系列的教学博客。于是乎想尽自己的微薄之力，让更多的人能够更好地理解算法，在未来求职的面试中不再因为它而与自己理想的公司失之交臂。\n\n我将与国内的教学方式和教学内容有所差别。形式上不再是只针对如何解决这个问题，因为只会解决问题并不代表真正理解这个问题。我会花一些篇幅着重介绍一些概念性的内容，这也是国内的教学最欠缺的部分。国内的课堂不会告诉你自然对数e与自然界生长的规律有关；学完了线性代数，你可能光学会了如何解行列式，却忽视了行列式也是有几何意义的。内容上不再按照“排序算法”、“搜索算法”等方式分类，而采用了问题解决的不同方式来划分，比如“暴力求解”、“分治法”、“动态规划”等等。当然，我也是参考了Levitin编写的教材[Introduction to The Design and Analysis of Algorithms, 3rd Edition](https://doc.lagout.org/science/0_Computer%20Science/2_Algorithms/Introduction%20to%20the%20Design%20and%20Analysis%20of%20Algorithms%20%283rd%20ed.%29%20%5BLevitin%202011-10-09%5D.pdf)。要是你觉得这本书讲得太基础，你也可以参考MIT的[《算法导论》](http://kddlab.zjgsu.edu.cn:7200/students/lipengcheng/%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA%EF%BC%88%E8%8B%B1%E6%96%87%E7%AC%AC%E4%B8%89%E7%89%88%EF%BC%89.pdf)。\n\n编程语言我会采用Python，因为Python是最接近这些英文书里用于讲解的伪代码，理解起来会更加方便。对于刚入门的小白来讲，Python的简洁不会让你因为不能理解编程语言本身而最终放弃了这门课程的学习。我会把每一节的内容的完整代码都放在我的[GitHub](https://github.com/infinityglow/Algorithm-and-Complexity)的 Algorithm 仓库里，方便学习后用代码真正实现它们。\n\n最后，要是讲解有任何疑问，欢迎在评论区留言。如果发现了有任何错误和表述不规范的地方，希望各位大佬轻喷，毕竟我也是第一次写博客，有错误也是在所难免的。\n\n## 总览\n\n### 介绍 (Introduction)\n\n&emsp;[1.1 什么是算法](https://infinityglow.github.io/study/algorithm/introduction/)\n\n### 基本知识 (Basic Knowledge)\n\n&emsp;[2.1 基本数据结构](https://infinityglow.github.io/study/algorithm/basic-knowledge/data-structure/)\n&emsp;[2.2 算法的问题类型](https://infinityglow.github.io/study/algorithm/basic-knowledge/problem-types/)\n\n### 复杂度分析 (Complexity Analysis)\n\n&emsp;[3.1 三种表示方法：O, Ω, Θ](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations/)\n&emsp;[3.2 复杂度分析（非递归）](https://infinityglow.github.io/study/algorithm/complexity-analysis/non-recursive/)\n&emsp;[3.3 复杂度分析（递归）](https://infinityglow.github.io/study/algorithm/complexity-analysis/recursive/)\n\n### 暴力求解 (Brute Force)\n\n&emsp;[4.1 冒泡排序与选择排序](https://infinityglow.github.io/study/algorithm/brute-force/bubble-selection-sort/)\n&emsp;[4.2 顺序查找与字符串匹配（BF）](https://infinityglow.github.io/study/algorithm/brute-force/string-matching/)\n&emsp;[4.3 图的两种遍历](https://infinityglow.github.io/study/algorithm/brute-force/graph-traversal/)\n&emsp;[4.4 最近点对与凸包问题（BF）](https://infinityglow.github.io/study/algorithm/brute-force/clo-pair-con-hull/)\n&emsp;[4.5 暴力搜索](https://infinityglow.github.io/study/algorithm/brute-force/exhaustive-search/)\n\n### 减治法（Decrease and Conquer）\n\n&emsp;[5.1 插入排序](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/insertion-sort/)\n&emsp;[5.2 拓扑排序](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/topo-sorting/)\n&emsp;[5.3 二分查找与二叉树](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/binary-search-tree/)\n&emsp;[5.4 插值查找](https://infinityglow.github.io/study/algorithm/decrease-and-conquer/interpolation-search/)\n\n### 分治法（Divide and Conquer）\n\n&emsp;[6.1 归并排序](https://infinityglow.github.io/study/algorithm/divide-and-conquer/merge-sort/)\n&emsp;[6.2 快速排序](https://infinityglow.github.io/study/algorithm/divide-and-conquer/quick-sort/)\n&emsp;[6.3 二叉树的遍历](https://infinityglow.github.io/study/algorithm/divide-and-conquer/bt-traversal/)\n&emsp;[6.4 最近点对与凸包问题（DC）](https://infinityglow.github.io/study/algorithm/divide-and-conquer/clo-pair-con-hull/)\n\n### 变治法（Transform and Conquer）\n\n&emsp;[7.1 预排序](https://infinityglow.github.io/study/algorithm/transform-and-conquer/presorting/)\n&emsp;[7.2 霍纳法则](https://infinityglow.github.io/study/algorithm/transform-and-conquer/horners-rule/)\n&emsp;[7.3 堆与堆排序](https://infinityglow.github.io/study/algorithm/transform-and-conquer/heap/)\n&emsp;[7.4 AVL树](https://infinityglow.github.io/study/algorithm/transform-and-conquer/AVL-tree/)\n&emsp;[7.5 红黑树](https://infinityglow.github.io/study/algorithm/transform-and-conquer/R&B-tree/)\n&emsp;[7.6 2-3树](https://infinityglow.github.io/study/algorithm/transform-and-conquer/two-three-tree/)\n\n### 时空权衡（Time Space Tradeoff）\n\n&emsp;[8.1 计数排序](https://infinityglow.github.io/study/algorithm/time-space-tradeoff/counting-sort/)\n&emsp;[8.2 字符串匹配（TST）](https://infinityglow.github.io/study/algorithm/time-space-tradeoff/string-matching/)\n&emsp;[8.3 哈希](https://infinityglow.github.io/study/algorithm/time-space-tradeoff/hashing/)\n\n### 动态规划（Dynamic Programming）\n\n&emsp;[9.1 关于钱的两个经典问题](https://infinityglow.github.io/study/algorithm/dynamic-programming/classic-problems/)\n&emsp;[9.2 背包问题（DP）](https://infinityglow.github.io/study/algorithm/dynamic-programming/knapsack-problem/)\n&emsp;[9.3 弗洛伊德算法](https://infinityglow.github.io/study/algorithm/dynamic-programming/Floyd-Warshall/)\n  \n### 贪心算法（Greedy Algorithm）\n\n&emsp;[10.1 普林姆算法](https://infinityglow.github.io/study/algorithm/greedy-algorithm/Prim/)\n&emsp;[10.2 克鲁斯卡尔算法](https://infinityglow.github.io/study/algorithm/greedy-algorithm/Kruskal/)\n&emsp;[10.3 迪克斯特拉算法](https://infinityglow.github.io/study/algorithm/greedy-algorithm/Dijkstra/)\n&emsp;[10.4 哈弗曼树](https://infinityglow.github.io/study/algorithm/greedy-algorithm/Huffman-tree/)\n\n### *高阶算法（Advanced Algorithm）\n\n&emsp;[*回溯](https://infinityglow.github.io/study/algorithm/advanced-algorithm/backtracking/)\n&emsp;[*分支限界](https://infinityglow.github.io/study/algorithm/advanced-algorithm/branch-and-bound/)\n&emsp;[*线性规划（单纯形法）](https://infinityglow.github.io/study/algorithm/advanced-algorithm/linear-programming/)\n&emsp;[*最大流问题](https://infinityglow.github.io/study/algorithm/advanced-algorithm/maximum-flow/)\n&emsp;[*匈牙利算法](https://infinityglow.github.io/study/algorithm/advanced-algorithm/hungarian-algorithm/)\n&emsp;[*千禧问题：P = NP ?](https://infinityglow.github.io/study/algorithm/advanced-algorithm/p-np/)\n\n"},{"title":"手把手教你用VPS搭建SS+bbr实现科学上网","url":"/others/ss_v2ray/ss/","content":"\n## 写在前面\n\n  首先先声明一下，本文不带有任何商业性质，单纯地是想方便海内外学生党使用Google、YouTube、Wikipedia等工具来查阅资料，作为一个Google和Wikipedia的重度使用者，有时候离开了这两样东西真的就没办法生活，所以做一个这方面的教程是非常有必要的。\n\n  如果你对访问外网的频率和带宽要求不高，用一般的免费vpn或者一些在线代理就足够了，市面上这些vpn哪个好用，哪个免费相信你们比我更清楚。如果要经常看YouTube高清视频或者连外服打游戏的小伙伴呢，这些免费但又不稳定的vpn自然就不能满足你们的需要了，所以得拥有一个自己专属的服务器来实现科学上网。\n\n## 基本原理\n\n![Shadowsocks基本原理](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/principle.png \"基本原理示意图\")\n\n  简单介绍一下ss的基本原理，其实ss就是隧道通信的一种，就是说从中国大陆直接访问Google、Facebook等黑名单网站是会被防火墙检测到并直接中断我们与这些服务器的连接的。这时候ss横空出世，作为一个中间者把我们将要发送给Google、Facebook服务器的请求经过本地(sslocal)加密，再将它们封装一下，与我们后面要部署的服务器达成通信协议。\n\n  当服务器(ssserver)端收到来自sslocal的数据之后，先解密，再将解密过后的数据发送给Google、Facebook服务器。当这些服务器把数据传回给ssserver过后，ssserver会将这些数据加密并打包发送给sslocal，sslocal拿到数据之后再进行解密，最后以网页的形式呈现出来。整个过程中，由于数据是进行加密的，所以防火墙是不知道我们在访问Google等外网的。\n\n  但据说最近ss已经能够被防火墙识别出来其特征，安全性存在一些漏洞，如果有空了可以再做一期v2ray的教程，其安全性和稳定性都要比ss要高。\n\n## 部署VPS\n\n  第一步需要部署我们的云服务器，这里先推荐一下[谷歌云](https://cloud.google.com)，可以免费试用一年的时间，并且还比较稳定，但有点麻烦的是需要你绑定信用卡，而且还必须是美国的。。。\n\n  这里我们演示的是一些主流服务商提供的VPS，话不多说，先推荐一波：\n\n  [搬瓦工](https://bandwagonhost.com)\n  [vultr](https://www.vultr.com)\n  [hostwind](https://www.hostwinds.com)\n  [time4vps](https://www.time4vps.com)\n\n  有的可能在国内被墙掉了，访问不了的只能自己想办法了。\n\n  这里以vultr为例，先进入官网。\n\n![vultr官网](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s1.png)\n  如果你是新用户，则需要先注册一下，这里点击“Sign up”。\n  点击之后，用你的邮箱作为用户名，然后自己创建一个密码。\n\n![vultr注册界面](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s2.png)\n  注册完以后登录即可。\n\n![vultr登录界面](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s3.png)\n  进入如下页面之后，选择“Product”，再点击右边的加号部署服务器。\n\n![部署服务器](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s4.png)\n![部署服务器](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s5.png)\n![部署服务器](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s6.png)\n\n  这里我们选择纽约的节点(因为最便宜)，然后系统选择Ubuntu 18.04，服务器配置根据自己的需求来选择。选完以后，点击下方的“Deploy Now”。付完款以后，将会出现如下的界面。\n![成功部署](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s7.png)\n\n## Shadowsocks服务器端配置\n\n  成功部署好VPS后就要开始服务器端的配置了。首先我们进入到服务器的信息页面(如下图所示)，我们需要记住这里的IP地址以及ssh远程登录时的密码。\n![服务器信息](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s10.png)\n\n  拿到IP地址以后可以先打开终端ping一下以确保服务器是否可用。我这里以Ubuntu系统作为演示，通信一切正常。\n![ping](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s9.png)\n\n  下一步就要用ssh命令远程登录我们的服务器了。Mac用户和Linux用户直接在终端使用ssh命令即可，Windows用户呢就要稍微麻烦一点，得先在网上下载PuTTY，然后再远程登录。\n\n``` bash\n$ ssh root@45.77.108.240\n```\n\n  按下回车后会叫你输入密码，也就是前面服务器信息里的密码。登录成功后就会出现下面的界面。\n\n![登录成功](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s12.png)\n\n  成功登录后，为了确保兼容性，需要更新一下软件包。\n\n``` bash\n$ sudo apt update\n$ sudo apt upgrade -y\n```\n\n  安装python和pip\n\n``` bash\n$ sudo apt install python\n$ sudo apt install python-pip\n```\n\n  安装shadowsocks\n\n``` bash\n$ pip install shadowsocks\n```\n  \n  在/etc/目录下创建shadowsocks.json配置文件\n\n``` bash\n$ vim /etc/shadowsocks.json\n```\n  \n  进入到vim界面之后，按i进入插入模式，然后按照下面的模板将服务器的配置信息写好(只需将端口号和密码改成自己想要的即可)，最后按”Esc“+“:wq”保存并退出\n\n```{\n    \"server\":\"0.0.0.0\",\n    \"server_port\": \"YOUR_PORT\",\n    \"local_address\":\"127.0.0.1\",\n    \"local_port\":\"1080\",\n    \"password\":\"YOUR_PASSWD\",\n    \"timeout\":\"500\",\n    \"method\":\"aes-256-cfb\"\n}```\n\n  配置文件写好以后就要启动我们的server了，在这里我们需要从配置文件中读取相应参数，因此ssserver命令需要加入-c参数。\n\n``` bash\n$ ssserver -c /etc/shadowsocks.json\n```\n\n  不出意外的话，第一次启动应该会报出“AttributeError: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1: undefined symbol: EVP_CIPHER_CTX_cleanup”这样的错，这篇[博客](https://blog.csdn.net/St_Louis/article/details/103171781)给出了完美的解决方案，只需要修改一个文件中的两行数据就行，这里我就不一一演示了。\n\n  如果想要在后台运行，只需要在最后加入“-d start”即可。\n\n``` bash\n$ ssserver -c /etc/shadowsocks.json -d start\n```\n\n## Shadowsocks客户端配置\n\n  客户端比服务器端就要好配置多啦，三大主流操作系统都支持[图形化界面](https://github.com/shadowsocks/shadowsocks-gui)，Linux甚至支持还命令行的客户端。这里以Linux的GUI为例，只需要把服务器端的IP地址、端口号、密码、加密方式按照你服务器端配置的方式填写正确即可，剩下的本地地址、本地端口、协议类型就按照下面的方式填写就行了。\n\n![客户端配置](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s26.png)\n\n## 浏览器配置\n\n  虽然我们的服务器端和客户端都已经配置好了，但要在浏览器里实现外网的访问还需要几个简单的步骤。\n\n  首先需要在[chrome网上应用店](https://chrome.google.com/webstore/category/extensions?hl=zh-CN)下载一个叫做SwitchyOmega的插件。下载完成后在你的浏览器右上方会有一个小圆圈，点击后选择Option。\n![插件](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s15.png)\n\n  进入后选择左边的proxy，Protocol选择Socks5，Sever选择127.0.0.1，Port为1080。\n![Proxy](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s16.png)\n\n  保存退出后，就能访问Google啦～\n\n  但这样有一个问题，所有的流量都走了代理服务器，而平时我们访问一些国内的网站是不需要走代理的，并且用代理服务器来访问国内的网站会非常的慢。可不可以实现自动分流呢？哈哈，SwitchyOmega给我们了这样一个“贴心”的服务：auto switch\n\n  选择左边的auto switch，再选择“Add a rule list”\n\n![auto switch](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s17.png)\n\n  在\"Rule list rules\"选择\"proxy，Rule List Format\"选择\"AutoProxy\"\n\n![auto switch](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s21.png)\n\n  我们可以自定义规则，哪些网址走代理，哪些直接访问。但这样一个一个输入实在太麻烦，我们直接从GitHub上搜索gfwlist即可。\n\n  选择第一项\n![github gfwlist](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s18.png)\n\n  进入后点击gfwlist.txt，复制URL到SwitchyOmega中的Rule List URL，再点击Download Profile Now\n![auto switch](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s19.png)\n\n  更改应用后，你会发现下方的Rule List Text出现了各种网址，这说明已经添加成功了。\n![auto switch](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s23.png)\n\n  这样当我们把SwitchyOmega的模式选择成auto switch后就能实现智能分流啦。\n\n## bbr加速\n\n  最后，为了让我们的网速飞起来，看YouTube视频不会卡顿，需要借助一个叫做bbr加速的东西。操作非常简单，只需要几个步骤就好。这里需要再次登录我们的VPS，在VPS里进行操作。\n\n  修改系统变量并保存\n``` bash\n$ echo \"net.core.default_qdisc=fq\" >> /etc/sysctl.conf\n$ echo \"net.ipv4.tcp_congestion_control=bbr\" >> /etc/sysctl.conf\n$ sysctl -p\n\n```\n\n  查看是否开启\n``` bash\n$ sysctl net.ipv4.tcp_available_congestion_control\n```\n\n  如果显示如下内容表示已经开启\n``` bash\n$ net.ipv4.tcp_available_congestion_control = reno cubic bbr\n```\n\n  查看BBR是否启动\n``` bash\n$ lsmod | grep bbr\n```\n\n  如果显示以下内容表示已经开启\n``` bash\n$ tcp_bbr                20480  25\n```\n\n  开启了bbr加速以后网速快的飞起，以我家的100M带宽为例，看YouTube 4k视频一点都不卡顿，网速也是相当给力的。\n![YouTube](https://infinityglow.github.io/others/ss_v2ray/screenshot_ss/s25.png)\n\n"},{"title":"什么是算法","url":"/study/algorithm/introduction/","content":"\n## 概念\n\n什么是算法？英文维基百科给出了这样的定义：“An algorithm is a finite sequence of well-defined, computer-implementable instructions, typically to solve a class of problems or to perform a computation.”翻译过来的意思就是一系列有限的、清晰定义的、可实现的计算机指令，并用以解决一类问题或进行计算。\n\n是不是被这么官方的定义搞懵了？在生活中一个最简单的类比就是烹饪。如果把要烧一道菜比作这里要解决的问题，那么菜谱中每一道工序，每一个步骤就是这道菜的“算法”了。但这样的类比也存在一些问题：我们的算法要求每一步都是要明确定义，也就是说不能有任何歧义的。还是拿做菜来讲，如果菜谱上是这样定义的：\n\n- 将油倒入锅中加热至七成热\n- 把鸡腿放入油锅中炸至金黄\n- 放入少许盐\n\n![炸鸡腿](https://infinityglow.github.io/study/algorithm/introduction/images/chicken-leg.jpg)\n\n以上的步骤虽然前后有逻辑性，最终能够做出炸鸡腿，但是这样的定义是不符合算法的规范的，因为这样的定义只具备了**经验性**（**empirical**），不具备**系统性**（**systematical**），计算机是读不懂人类的这些经验的。所以，正确的姿势应该是这样的：\n\n- 将200ml的色拉油放入铁锅中，打开电炉，调至第9档，当油温达到200°C后停止加热\n- 把碗里的鸡腿依次放入油锅中煎炸，直至鸡腿表面呈现出 #FF9900 (金黄色RGB的十六进制表示法)\n- 根据鸡腿的重量（g）和一个映射函数 f(x) 计算出需要放置的盐的重量（g），将其放入锅中\n\n这样我们的计算机就好理解多啦～\n\n![happy](https://infinityglow.github.io/study/algorithm/introduction/images/happy.jpg)\n\n## 解决的问题\n\n了解完了算法的概念，那么算法是要用来干什么的呢？前面提到了是用来解决一类问题，这样的问题可以是[排序](https://infinityglow.github.io/tags/sorting/), [查找](https://infinityglow.github.io/tags/search/)，最优化问题等等。总之，这些问题大部分都是有确定解的，我们只需要用其中的一种算法找到它们即可。\n\n但是，仅仅找到了算法来解决这些问题是远远不够的。我们还需要考虑这个算法的效率如何，也就是对其进行[复杂度](https://infinityglow.github.io/study/algorithm/complexity-analysis/three-notations)分析。这里暂时不做讨论，先举一个经典的算法问题：扔鸡蛋问题。假设楼高为100层，给你2个鸡蛋，你需要试出来从第几层往下扔鸡蛋刚好会碎。你可能首先想到的是从第一层开始一层一层地扔直到鸡蛋摔碎，但是这样你可能最多扔99次（假设从100层往下扔鸡蛋才碎），而且你没有利用上第二个鸡蛋。一些聪明的同学可能又想到了用一个鸡蛋十层十层地往上扔，如果碎了就在两个十层之间一层一层地往上扔。这样最多只要扔19次，已经比之前的方法有了明显的进步，这就是算法要考虑的效率问题。事实上，这个问题的最优解是最多扔14次，需要后面要讲到的[动态规划](https://infinityglow.github.io/tag/dp/)。\n\n![扔鸡蛋](https://infinityglow.github.io/study/algorithm/introduction/images/egg.png)\n\n## 例子\n\n让我们看一道完整的例子，求两个数的最大公约数。相信在中学阶段老师就告诉过你们把两个数的因子提取出来，然后把所有共同的因子相乘得到结果。这里我们对这种方法不做讨论，让我们先看看一种高效的解法：**欧几里得算法**（**Euclid's algorithm**）。\n\n欧几里得算法又叫辗转取余法，其原理是两个数的最大公约数等于较小数与两数取余的最大公约数，用数学语言来描述的话就是 `gcd(m, n) = gcd(n, m mod n)`。但这只是其中的一步，什么时候才返回我们想要的结果呢？这就需要用算法语言来描述这个过程，这种语言可以是自然语言，也可以是数学语言（伪代码）。让我们先以自然语言为例吧。\n\n- 第一步：如果 n = 0，返回m；否则执行第二步。\n- 第二步：m 除以 n，将余数赋给变量r。\n- 第三步：把 n 赋给 m，r 赋给 n。执行第一步。\n\n如果用伪代码来表示的话就是这样的：\n\n![伪代码](https://infinityglow.github.io/study/algorithm/introduction/images/Euclid.png)\n\n最后，让我们用Python来实现这个函数吧。\n\n```\ndef gcd(m, n):\n    while n != 0:\n        r = m\n        m = n\n        n = r % n\n        gcd(m, n)\n    return m\n```\n\n[本节全部代码](https://github.com/infinityglow/Algorithm-and-Complexity/tree/master/Introduction)\n\n"}]